---
title: "LEAD Data Analysis"
format: html
---

# Load packages

```{r, warning=FALSE, echo=FALSE, output = FALSE, include=FALSE}
library(flextable)
library(table1)
library(dplyr)
library(tibble)
library(misty)
library(officer)
library(tidyverse)
library(readr)
library(purrr)
library(stringr)
library(mice)
library(lubridate)
```

# Load cleaned data

Load the participant, self report, LEAD panel assessment and sociodemographic information datasets

```{r}
#| warning: false
socio_demo <- readRDS("../data/cleaned_rds_files/sociodemographic_information_import.rds")
observational_measures <- readRDS("../data/cleaned_rds_files/observational_measures_import.rds")
lead_panel_assessment <- readRDS("../data/cleaned_rds_files/lead_panel_assessment_import.rds")
participant <- readr::read_rds("../data/cleaned_rds_files/participant_import.rds")
```

# Data preparation

Prepare and then merge the relevant variables in the self report, LEAD panel assessment and sociodemographic information data sets into one data frame.

## Participant data

This data was collected by MedStar at the initial 911 response. It includes the results of the initial DETECT screening. We will need those screening results below to compare with LEAD panel findings. 

```{r}
#| eval: false

# Look for duplicate by (MedStar ID) records
participant |> 
  group_by(medstar_id) |> 
  count() |> 
  filter(n > 1)

# 2023-08-01: No duplicate rows by MedStar ID
```

```{r}
# Keep only the columns of interest
participant <- participant |> 
  select(medstar_id, xc_detect_positive_summary_count:xc_detect_status_2cat_f)
```

## Sociodemographic Information

This data was collected during the DETECT follow-up interview. It includes participant sociodemographic information like race, household income and others. We will compare LEAD screening results across different sociodemographic categories. 

```{r}
# Select relevant variables of interest from sociodemographic information df
soc_dem <- socio_demo %>%
  select(medstar_id, sode_hispanic_4cat_f, sode_race, sode_income_9cat_f)

# Create dummy variables for race
soc_dem <- soc_dem %>% 
  mutate(
    american_indian_or_alaska_native               = ifelse(grepl("American Indian or Alaska Native", sode_race),1, 0),
    asian                                          = ifelse(grepl("Asian", sode_race),1, 0),
    black_or_african_american                      = ifelse(grepl("Black or African American", sode_race),1, 0),
    native_hawaiian_or_other_pacific_islander      = ifelse(grepl("Native Hawaiian or Other Pacific Islander", sode_race),1, 0),
    white                                          = ifelse(grepl("White", sode_race),1, 0),
    other                                          = ifelse(grepl("Other", sode_race),1, 0)
  )

# Create factor variables and set labels
soc_dem <- soc_dem %>% 
  mutate(
    across(
      .cols = american_indian_or_alaska_native:other,
      .fns  = ~ factor(.x,
                       levels = c(0,1), 
                       labels = c("No", "Yes")
      ),
      .names = "{col}"
    )
  )
    
```

## MedStar Medic Assessment (Observational Measures Dataset)

This data comes from the DETECT follow-up interviews. It is a collection of medic EM responses to questions about whether or not they believe abuse has occurred based on provided definitions, signs and symptoms. We will compare these the Medic EM Assessment results to the LEAD Panel Assessment results.

ðŸ”´ If this is the DETECT tool filled out at the follow-up interview, I think we will also want the results of the DETECT tool filled out at the initial 911 call. Because we want to be able to say, "At the initial 911 response the DETECT tool was [positive/negtive] for EM. The lead panel then reviewed the case and determined that EM [was/was not] occuring. X porportion of the time, the initial DETECT screening and the LEAD panel determination agreed with each other."

```{r}
obs_meas <- observational_measures %>% 
  select(medstar_id, at_physical_4cat_f: at_self_4cat_f)
```

### Any positive determinations across all subtypes

Create a factor column 'medic_abuse_any' that indicates if an EM medic believes at least one type of abuse is present or none is present.

```{r}
obs_meas <- obs_meas %>%
  mutate(
    medic_abuse_any = case_when(
      if_any(at_physical_4cat_f : at_self_4cat_f, ~. == "Yes")  ~ 1,
      if_all(at_physical_4cat_f : at_self_4cat_f, ~. == "No")   ~ 0,
      TRUE                                                      ~ NA
    )
  )%>%
  mutate(
    medic_abuse_any = factor(
      medic_abuse_any,
      levels = c(0, 1),
      labels = c("No", "Yes")
    )
  )
```

## LEAD Panel Assessment

This data comes from participant abuse assessments by a Longitudinal, Experts, All Data (LEAD) panel. It will be analysed using variables in the sociodemographic, participant and observational measures datasets.

```{r}
# Select relevant variables from LEAD panel assessment df
lpa <- lead_panel_assessment %>%
  select(medstar_id, panelist_name_10cat_f:xc_assessment_screened_2cat_f)
```

```{r}
# Subset with initial assessment only
initial <- lpa %>% filter(assessment_type_3cat_f == "Initial assessment")

# Subset with Secondary assessment only
secondary <- lpa %>% filter(assessment_type_3cat_f == "Secondary assessment")

# Subset with Post-detect assessment only
post_detect <- lpa %>% filter(assessment_type_3cat_f == "Post-detect assessment")
```

## ðŸ”´ Panelist multiple assessment data error

Look at medstar_id 47311d550da4471297501ae2b3b03b02. It looks like Jason completed two initial assessments, which shouldn't happen. My guess is that the second initial assessment should have been a secondary assessment and he accidentally clicked the wrong option in FM Pro. We could check this by:
1. Check to see if the there is already a secondary assessment for Jason for 47311d550da4471297501ae2b3b03b02.
2. Check the time stamp on the votes. The secondary assessment should come after the initial assessment (probably on a different day).
3. If there truly are multiple initial assessments, then we need to check if there is any difference between them. If not, then just keep the final row (in terms of time stamp).
4. If there ARE differences, this is trickier. I'm leaning towards keeping the final row here too, but we should look at some examples before making a final decision.

### Identify Medstar IDs with data error

Create a function that creates a subset data frame containing Medstar IDs with multiple assessments for the same panelists and identifies the specific issues by adding the following columns:

_same_score_     - For each MedStar ID, are all the scores assigned by the same panelist identical or different.

_over_24_hours_  - For each MedStar ID with multiple assessments for the same panelist, were the assessments performed within one day of                      each other?

_all_na_         - For each MedStar ID with multiple assessments for the same panelist, is any of the assessments filled with missing                         values?

```{r}
error_check <- function(assessment) {
  group <- c('physical_abuse_2cat', 'sexual_abuse_2cat', 'emotional_psycho_abuse_2cat', 'neglect_2cat', 
             'self_neglect_2cat', 'financial_exploitation_2cat', 'abandonment_2cat')
  multiple_assessment <- lead_panel_assessment %>% filter(assessment_type_3cat_f == assessment) %>% 
    group_by(medstar_id, panelist_name_10cat_f) %>% 
    reframe(medstar_id, assessment_type_3cat_f, panelist_name_10cat_f, x_created_timestamp,
            multiple_count = length(panelist_name_10cat_f), 
            physical_abuse_2cat, sexual_abuse_2cat, emotional_psycho_abuse_2cat, neglect_2cat, 
            self_neglect_2cat, financial_exploitation_2cat, abandonment_2cat, xc_assessment_screened_2cat) %>%
    filter(multiple_count > 1) %>%
    group_by(medstar_id, panelist_name_10cat_f, sexual_abuse_2cat, emotional_psycho_abuse_2cat, neglect_2cat,
             self_neglect_2cat, financial_exploitation_2cat, abandonment_2cat) %>% 
    mutate(
      same_score          = n()>1
    ) %>%
    ungroup() %>%
    mutate(
      all_na              = case_when(
        if_all(group,     ~is.na(.))    ~ "all",
        if_all(group,     ~!is.na(.))   ~ "none",
        TRUE                            ~ "some",
      )
    ) %>%
    ungroup() %>%
    group_by(medstar_id, panelist_name_10cat_f) %>%
    mutate(
      over_24_hours       = ifelse((as.numeric(difftime(last(x_created_timestamp), 
                                                        first(x_created_timestamp), units = "hours")) > 24), 1,0)
    )
  multiple_assessment
}
```

#### Initial Assessments

```{r}
initial_error <- error_check("Initial assessment")

# Create a column that indicates if there are secondary assessments for each MedStar ID with multiple assessments for the same panelists.


  
```


#### Secondary Assessments
```{r}


secondary_error <- error_check("Secondary assessment")
```

```{r}
# Post-detect assessments

post_detect_error <- error_check("Post-detect assessment")
```

# ðŸ”´ Ebie, please review this.

### Create overall EM determination columns

For each medstar_id reviewed by the LEAD panel, we want to calculate:

1. Create a column containing the number of positive determinations at each assessment (initial, secondary, and post-DETECT) for each subtype of EM.

2. Create a column containing the proportion (denominator is number of non-missing votes) of positive determinations at each assessment (initial, secondary, and post-DETECT) for each subtype of EM.

### Total and proportion of positive votes for each Medstar iD

# ðŸ”´ Ebie, please review this.

The code below is not actually add new columns to the df called "initial". It is creating a new df (still called initial) that has different columns of summary information. We should either use `mutate` to add the summary columns to initial or we should name this new df something else.

```{r}
initial |> 
  group_by(medstar_id) |> 
  mutate(
    across(
      .cols  = physical_abuse_2cat:abandonment_2cat,
      .fns   = ~ sum(.x),
      .names = "{col}_total"
    )
  ) |> filter(self_neglect_2cat_total > 0)
```


Create summary dataframes for each assessment that include calculated columns indicating the total number of positive votes and the proportion of positive votes for each MedStar ID.

```{r}
# Create a positive vote summary function that will be applied to each of the three assessment data frames.

pos_votes <- function(assessment) {
  assessment %>% 
  group_by(medstar_id) %>% 
  reframe(
    across(
      .cols  = c(physical_abuse_2cat : abandonment_2cat, xc_assessment_screened_2cat),
      .fns   = ~ sum(.x),
      .names = "{col}_t"
    ),
    assessment_type_3cat_f  = unique(assessment_type_3cat_f),
    across(
      .cols  = physical_abuse_2cat_t : xc_assessment_screened_2cat_t,
      .fns   = ~ case_when(
        .x   == 0  ~ 0,
        .x  !=  0  ~ .x/n()
      ),
      .names = "{col}_p"
    )
  ) %>%
  rename_with(
    .cols   = ends_with("_t"), 
    .fn     = ~ gsub("2cat_t", "total", .x)
  ) %>% 
  rename_with(
    .cols   = ends_with("_p"), 
    .fn     = ~ gsub("2cat_t_p", "prop", .x)
  )
}
```

```{r}
# Initial Assessments

initial_pos_votes <- pos_votes(initial)
```

```{r}
# Secondary Assessments

secondary_pos_votes <- pos_votes(secondary)
```

```{r}
# Post-detect assessments

post_detect_pos_votes <- pos_votes(post_detect)
```

#### Any positive determinations for each subtypes

3. Create a dichotomous variable that indicates if there were _any_ positive determinations at each assessment (initial, secondary, and post-DETECT) for each subtype of abuse.

```{r}
any_pos <- function(assessment_pos_votes) {
  assessment_pos_votes %>% 
    mutate(
      across(
        .cols   = physical_abuse_total : xc_assessment_screened_total,
        .fn     = ~ case_when(
          .x    == 0 ~ 0,
          .x    >  0 ~ 1
        ),
        .names  = "{col}_any"
      ),
      across(
        .cols   = ends_with("_any"),
        .fns    = ~ factor(.x, 
                      levels = c(0,1),
                      labels = c("No", "Yes")),
      .names = "{col}"
      )
    ) %>%
    rename_with(
      .cols   = ends_with("_any"), 
      .fn     = ~ gsub("total_any", "any", .x)
    )
  
}
```

```{r}
# Initial Assessments

initial_pos_votes <- any_pos(initial_pos_votes)
```

```{r}
# Secondary Assessments

secondary_pos_votes <- any_pos(secondary_pos_votes)
```

```{r}
# Post-detect assessments

post_detect_pos_votes <- any_pos(post_detect_pos_votes)
```

#### Majority vote variable for each abuse type

Create columns that indicate the final LEAD Assessment determination based on majority vote. Final determination will be by majority (more than half) vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)

```{r}
final_det <- function(assessment_pos_votes) {
  assessment_pos_votes %>% 
    mutate(
      across(
        .cols   = physical_abuse_prop : xc_assessment_screened_prop,
        .fn     = ~ case_when(
          .x    <= 0.5         ~ 0,
          .x    >  0.5         ~ 1
        ),
        .names  = "{col}_det"
      ),
      across(
        .cols   = ends_with("_det"),
        .fns    = ~ factor(.x, 
                      levels = c(0,1),
                      labels = c("No", "Yes")),
      .names = "{col}"
      )
    ) %>%
    rename_with(
      .cols   = ends_with("_det"), 
      .fn     = ~ gsub("prop_det", "det", .x)
    )
}
```

```{r}
# Initial Assessments

initial_pos_votes <- final_det(initial_pos_votes)
```

```{r}
# Secondary Assessments

secondary_pos_votes <- final_det(secondary_pos_votes)
```

```{r}
# Post-detect assessments

post_detect_pos_votes <- final_det(post_detect_pos_votes)
```

#### Any positive determinations across all subtypes

Create a dichotomous variable that indicates if there were _any_ positive determinations at each assessment (initial, secondary, and post-DETECT) across _all_ subtypes of EM.

```{r}
abuse_any <- function(assessment_pos_votes) {
  assessment_pos_votes %>%
    mutate(
      abuse_any = case_when(
        if_any(physical_abuse_det : abandonment_det, ~. == "Yes")  ~ 1,
        if_all(physical_abuse_det : abandonment_det, ~. == "No")   ~ 0,
        TRUE                                                       ~ NA
      )
    ) %>%
    mutate(
        abuse_any = factor(
        abuse_any,
        levels = c(0, 1),
        labels = c("No", "Yes")
      )
    )
}
```

```{r}
# Initial Assessments

initial_pos_votes <- abuse_any(initial_pos_votes)
```

```{r}
# Secondary Assessments

secondary_pos_votes <- abuse_any(secondary_pos_votes)
```

```{r}
# Post-detect assessments

post_detect_pos_votes <- abuse_any(post_detect_pos_votes)
```

```{r}
# Merge the initial_pos_votes and secondary_pos_votes data sets, keeping only the secondary_pos_votes for each medstar_id when it is available
final_determination <- initial_pos_votes[!initial_pos_votes$medstar_id %in% secondary_pos_votes$medstar_id,]
final_determination <- rbind(final_determination, secondary_pos_votes)
```

## Merge observational measures, sociodemographic and LEAD dateframes

```{r}
# Merge subset dfs into a new df

final_determination <- purrr::reduce(list(final_determination, soc_dem, obs_meas), dplyr::left_join, by = 'medstar_id')
final_det_initial   <- purrr::reduce(list(initial, soc_dem, obs_meas), dplyr::left_join, by = 'medstar_id')
final_det_sec       <- purrr::reduce(list(secondary, soc_dem, obs_meas), dplyr::left_join, by = 'medstar_id')
final_det_post      <- purrr::reduce(list(post_detect, soc_dem, obs_meas), dplyr::left_join, by = 'medstar_id')
```

# Analaysis

## Number and proportion of assessements completed by type of assesement

How many unique MedStar IDs went to the LEAD panel for review?

```{r, include=FALSE}
unique_medstar_ids <- unique(lpa$medstar_id) |> length()
cat("Unique MedStar ID's =", unique_medstar_ids)
```

### Initial assessment

```{r, include=FALSE}
unique_medstar_ids_initial <- unique(initial$medstar_id) |> length()
cat("Unique MedStar ID's at intitial assessment =", unique_medstar_ids_initial)
```

```{r, include=FALSE}
cat("Proportion of MedStar ID's with an intitial assessment =", unique_medstar_ids_initial/unique_medstar_ids)
```

### Secondary assessment

```{r, include=FALSE}
unique_medstar_ids_secondary <- unique(secondary$medstar_id) |> length()
cat("Unique MedStar ID's at secondary assessment =", unique_medstar_ids_secondary)
```

```{r, include=FALSE}
cat("Proportion of MedStar ID's with an secondary assessment =", unique_medstar_ids_secondary/unique_medstar_ids)
```

### Post-DETECT assessment

```{r, include=FALSE}
unique_medstar_ids_post_detect <- unique(post_detect$medstar_id) |> length()
cat("Unique MedStar ID's at post-DETECT assessment =", unique_medstar_ids_post_detect)
```

```{r, include=FALSE}
cat("Proportion of MedStar ID's with an post-DETECT assessment =", unique_medstar_ids_post_detect/unique_medstar_ids)
```

### Summary table
```{r}
sum_table <- data.frame(
                        Value = c("Unique MedStar ID's at intitial assessment", 
                                  "Unique MedStar ID's at secondary assessment", 
                                  "Unique MedStar ID's at post-DETECT assessment", 
                                  "Total unique MedStar ID's across all assessments"),
                        Count = c(unique_medstar_ids_initial, unique_medstar_ids_secondary,
                                  unique_medstar_ids_post_detect, unique_medstar_ids),
                        Proportion = c((unique_medstar_ids_initial/unique_medstar_ids), 
                                       (unique_medstar_ids_secondary/unique_medstar_ids), 
                                       (unique_medstar_ids_post_detect/unique_medstar_ids), 
                                       1)
                        ) %>%
  flextable()
# Set caption

sum_table <- set_caption(sum_table, "Summary of Unique Medstar IDs for the LEAD Assessment Data")
sum_table <- bold(sum_table, i = 4, bold = TRUE)
sum_table <- width(sum_table, width = 2)


sum_table
```

## Missing data summary

```{r, fig.width = 15}
fd_m <- final_determination %>% 
  select(
    physical_abuse_det: at_self_4cat_f,  
    )%>% md.pattern(., plot = T, rotate.names = T)
```


# ðŸ”´ NOTE

Before we analyze race, we want to know the number and proportion of determinations overall. Secondarily, we will repeat the analysis by race/ethnicity (and probably a bunch of other characteristics). Let's don't drop any rows yet that have NA for race/ethnicity. Only drop rows that have NA for determinations (hopefully, there aren't any).

## Sumary Statistics Tables

### Determinations Overall

#### Final determinations for the secondary assessment except when not available (initial assessment in this case)

```{r}
# Create caption/ title
cap_1  <- "Summary Statistics for Abuse Determinations Overall - Secondary (Initial When Unavailable)"


overall_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + abandonment_det + financial_exploitation_det + self_neglect_det + abuse_any, 
               data = final_determination, 
               caption = cap_1)
overall_tab <- t1flex(overall_tab, tablefn = c("qflextable", "flextable", "regulartable"))
overall_tab <- width(overall_tab, width = 3)
overall_tab
```


#### Final determinations for the intial assessment

```{r}
# Create caption/ title
cap_1  <- "Summary Statistics for Abuse Determinations Overall - Intial Assessment"


initial_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + abandonment_det + financial_exploitation_det + self_neglect_det + xc_assessment_screened_det, 
               data = final_det_initial, 
               caption = cap_1)
initial_tab <- t1flex(initial_tab, tablefn = c("qflextable", "flextable", "regulartable"))
initial_tab <- width(initial_tab, width = 3)
initial_tab
```

#### Final determinations for the secondary assessment

```{r}
# Create caption/ title
cap_1  <- "Summary Statistics for Abuse Determinations Overall - Secondary Assessment"


sec_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + abandonment_det + financial_exploitation_det + self_neglect_det + xc_assessment_screened_det, 
               data = final_det_sec, 
               caption = cap_1)
sec_tab <- t1flex(sec_tab, tablefn = c("qflextable", "flextable", "regulartable"))
sec_tab <- width(sec_tab, width = 3)
sec_tab
```

#### Final determinations for the post detect assessment

```{r}
# Create caption/ title
cap_1  <- "Summary Statistics for Abuse Determinations Overall - Post-Detect Assessment"


post_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + abandonment_det + financial_exploitation_det + self_neglect_det + xc_assessment_screened_det, 
               data = final_det_post, 
               caption = cap_1)
post_tab <- t1flex(post_tab, tablefn = c("qflextable", "flextable", "regulartable"))
post_tab <- width(post_tab, width = 3)
post_tab
```


### Race/ Ethnicity stratified by abuse determination

```{r}
# Remove missing rows for LEAD data
fd_na <- final_determination %>% drop_na(physical_abuse_det: 	
xc_assessment_screened_det)
```


#### Abuse Determination Overall by Race/ Ethnicity
The data set includes the Secondary Assessment (initial When unavailable)

```{r}
# Create caption/ title
cap_1  <- "Summary Statistics for Race/ Ethnicity by Abuse Determination"


abuse_any_tab <- table1(~ sode_hispanic_4cat_f + american_indian_or_alaska_native + asian + black_or_african_american + native_hawaiian_or_other_pacific_islander + white + other| abuse_any, 
               data = fd_na, 
               caption = cap_1)
abuse_any_tab <- t1flex(abuse_any_tab, tablefn = c("qflextable", "flextable", "regulartable"))
abuse_any_tab <- width(abuse_any_tab, width = 3)
abuse_any_tab
```

#### Abuse Determination Overall by Household Income
The data set includes the Secondary Assessment (initial When unavailable)

```{r}
# Create caption/ title
cap_1  <- "Summary Statistics for Household Income by Abuse Determination"


income_tab <- table1(~ sode_income_9cat_f | abuse_any, 
               data = fd_na, 
               caption = cap_1)
income_tab <- t1flex(income_tab, tablefn = c("qflextable", "flextable", "regulartable"))
income_tab <- width(income_tab, width = 3)
income_tab
```

#### MedStar Medic vs LEAD Abuse Determination

```{r}
# Create caption/ title
cap_1  <- "Summary Statistics for MedStar Medic Abuse Determinations"


medic_tab <- table1(~ at_physical_4cat_f + at_sexual_4cat_f + at_emotional_4cat_f + at_neglect_4cat_f + at_abandon_4cat_f + at_financial_4cat_f + at_self_4cat_f + medic_abuse_any,
               data = final_determination,
               caption = cap_1)
medic_tab <- t1flex(medic_tab, tablefn = c("qflextable", "flextable", "regulartable"))
medic_tab <- width(medic_tab, width = 3)
medic_tab
```

```{r}
# Create caption/ title
cap_1  <- "Summary Statistics for Overall MedStar Medic Abuse Abuse Determinations by Overall LEAD Determinations"


mvl_tab <- table1(~ medic_abuse_any | abuse_any,
               data = fd_na,
               caption = cap_1)
mvl_tab <- t1flex(mvl_tab, tablefn = c("qflextable", "flextable", "regulartable"))
mvl_tab <- width(mvl_tab, width = 3)
mvl_tab
```
