---
title: "LEAD Data Analysis"
format: html
---

# Load packages

```{r, warning=FALSE, echo=FALSE, output = FALSE, include=FALSE}
library(flextable)
library(table1)
library(dplyr)
library(tibble)
library(misty)
library(officer)
library(tidyverse)
library(readr)
library(purrr)
library(stringr)
library(mice)
library(lubridate)
library(writexl)
```

# Load cleaned data

Load the participant, self report, LEAD panel assessment,observational measures and sociodemographic information datasets

```{r}
#| warning: false
socio_demo <- readRDS("../data/cleaned_rds_files/sociodemographic_information_import.rds")
observational_measures <- readRDS("../data/cleaned_rds_files/observational_measures_import.rds")
lead_panel_assessment <- readRDS("../data/cleaned_rds_files/lead_panel_assessment_import.rds")
participant <- readr::read_rds("../data/cleaned_rds_files/participant_import.rds")
```

# Data preparation

Prepare and then merge the relevant variables in the self report, LEAD panel assessment and sociodemographic information data sets into one data frame.

## Participant data

This data was collected by MedStar at the initial 911 response. It includes the results of the initial DETECT screening. We will need those screening results below to compare with LEAD panel findings. 

We will need the results of the DETECT tool filled out at the initial 911 call because we want to be able to say, "At the initial 911 response the DETECT tool was [positive/negtive] for EM. The lead panel then reviewed the case and determined that EM [was/was not] occuring. X porportion of the time, the initial DETECT screening and the LEAD panel determination agreed with each other."


```{r}
#| eval: false

# Look for duplicate by (MedStar ID) records
participant |> 
  group_by(medstar_id) |> 
  count() |> 
  filter(n > 1)

# 2023-08-01: No duplicate rows by MedStar ID
```

```{r}
# Keep only the columns of interest
parti <- participant |> 
  select(
    medstar_id, x_created_timestamp, x_record_month, x_record_year,
    incident_timestamp, unit_arrived_timestamp, complaint_reported,
    age, incident_result, symptom_list, xc_detect_positive_summary_count,
    x_caregiver_lack_knowledge_2cat_f:xc_detect_status_2cat_f
  )
```

## Sociodemographic Information

This data was collected during the DETECT follow-up interview. It includes participant sociodemographic information like race, household income and others. We will compare LEAD screening results across different sociodemographic categories. 

```{r}
# Select relevant variables of interest from sociodemographic information df
soc_dem <- socio_demo %>%
  select(medstar_id, sode_hispanic_4cat_f, sode_race : other, sode_income_9cat_f)

```

## MedStar Medic Assessment (Observational Measures Dataset)

This data comes from the DETECT follow-up interviews. It is a collection of medic EM responses to questions about whether or not they believe abuse has occurred based on provided definitions, signs and symptoms. We will compare these the Medic EM Assessment results to the LEAD Panel Assessment results.

```{r}
obs_meas <- observational_measures %>% 
  select(medstar_id, at_physical_4cat_f: at_self_4cat_f)
```

### Any positive determinations across all subtypes

Create a factor column 'medic_abuse_any' that indicates if an EM medic believes at least one type of abuse is present or none is present.

```{r}
obs_meas <- obs_meas %>%
  mutate(
    medic_abuse_any = case_when(
      if_any(at_physical_4cat_f : at_self_4cat_f, ~. == "Yes")  ~ 1,
      if_all(at_physical_4cat_f : at_self_4cat_f, ~. == "No")   ~ 0,
      TRUE                                                      ~ NA
    )
  )%>%
  mutate(
    medic_abuse_any = factor(
      medic_abuse_any,
      levels = c(0, 1),
      labels = c("No", "Yes")
    )
  )
```

## LEAD Panel Assessment

This data comes from participant abuse assessments by a Longitudinal, Experts, All Data (LEAD) panel. It will be analysed using variables in the sociodemographic, participant and observational measures datasets.

```{r}
# Select relevant variables from LEAD panel assessment df
lpa <- lead_panel_assessment %>%
  select(medstar_id, panelist_name_10cat_f, x_created_timestamp, assessment_type_3cat_f : xc_assessment_screened_2cat_f)
```

```{r}
# Subset with initial assessment only
initial_e <- lpa %>% filter(assessment_type_3cat_f == "Initial assessment")

# Subset with Secondary assessment only
secondary_e <- lpa %>% filter(assessment_type_3cat_f == "Secondary assessment")

# Subset with Post-detect assessment only
post_detect_e <- lpa %>% filter(assessment_type_3cat_f == "Post-detect assessment")
```

### ðŸ”´ Panelist multiple assessment data error

Look at medstar_id 47311d550da4471297501ae2b3b03b02. It looks like Jason completed two initial assessments, which shouldn't happen. My guess is that the second initial assessment should have been a secondary assessment and he accidentally clicked the wrong option in FM Pro. We could check this by:
1. Check to see if the there is already a secondary assessment for Jason for 47311d550da4471297501ae2b3b03b02.
2. Check the time stamp on the votes. The secondary assessment should come after the initial assessment (probably on a different day).
3. If there truly are multiple initial assessments, then we need to check if there is any difference between them. If not, then just keep the final row (in terms of time stamp).
4. If there ARE differences, this is trickier. I'm leaning towards keeping the final row here too, but we should look at some examples before making a final decision.

#### Identify Medstar IDs with data error

Create a function that identifies the specific issues and indicates whether a row should be excluded or not by adding the following columns:

_multiple_count_ - Indicate the number of rows for each panelist under each MedStar ID.

_same_score_     - For each MedStar ID, are all the scores assigned by the same panelist identical or different.

_over_24_hours_  - For each MedStar ID with multiple assessments for the same panelist, were the assessments performed within one day of each other?
_most_recent_    - For each MedStar ID with multiple assessments for the same panelist, was the entry for the specified row the most recent?

_all_na_         - Are all, some or none of the assessment values missing for the specified row?
_remove_         - Should this row be removed or is further review required to determine this based on the rules below?

                  1. Identical duplicates: Keep the most recent row.
                  2. Additional entries with all values missing : Remove rows with all missing vote values

```{r}
error_check <- function(assessment) {
  
  # Create a vector of abuse type columns. Will be used for grouping below.
  group <- c('physical_abuse_2cat', 'sexual_abuse_2cat', 'emotional_psycho_abuse_2cat', 'neglect_2cat', 
             'self_neglect_2cat', 'financial_exploitation_2cat', 'abandonment_2cat')
  
  # Add a column to the data frame -- multiple_count -- that is equal to the 
  # number of rows in the data frame for each combination of medstar ID and
  # panelist name.
  multiple_assessment <- assessment %>%
    group_by(medstar_id, panelist_name_10cat_f) %>% 
    mutate(
      multiple_count = length(panelist_name_10cat_f)
    ) %>%
    ungroup()
  
  # For each MedStar ID, are all the scores assigned by the same panelist identical or different.
  multiple_assessment <- multiple_assessment |> 
    group_by(
      medstar_id, panelist_name_10cat_f, sexual_abuse_2cat, emotional_psycho_abuse_2cat, neglect_2cat,
      self_neglect_2cat, financial_exploitation_2cat, abandonment_2cat
    ) %>%
    mutate(
      same_score = n() > 1
    ) %>%
    ungroup()
  
  # Are all, some. or none of the assessment values missing for the specified row?
  multiple_assessment <- multiple_assessment |> 
    mutate(
      all_na = case_when(
        if_all(all_of(group), ~ is.na(.))  ~ "all",
        if_all(all_of(group), ~ !is.na(.)) ~ "none",
        TRUE                               ~ "some"
      )
    ) %>%
    ungroup()
  
  # For each MedStar ID with multiple assessments for the same panelist, were 
  # the assessments performed within one day of each other?
  multiple_assessment <- multiple_assessment |>
    group_by(medstar_id, panelist_name_10cat_f) %>%
    mutate(
      over_24_hours = ifelse(
        (as.numeric(difftime(last(x_created_timestamp), first(x_created_timestamp), units = "hours")) > 24), 1, 0
      )
    )
  
  # For each MedStar ID with multiple assessments for the same panelist, was the entry for the specified row the most recent?
  multiple_assessment <- multiple_assessment |>
    mutate(
      most_recent = ifelse(x_created_timestamp == max(x_created_timestamp), "Yes", "No")
    )
  
  # Should this row be removed or is further review required to determine this 
  # based on the rules below?
  multiple_assessment <- multiple_assessment |>
    mutate(
      remove  = case_when(
        # Case when the error is present and the scores are not identical. All of the rows being compared have one or more missing
        # scores and at least one of the rows being compared does not have all of the scores missing. Marks such cases
        # for individual review
        multiple_count > 1 & same_score == FALSE & all(all_na != "none") & any(all_na != "all") ~ "Individual review",
        
        # Case when the error is present, the scores are not identical and at least one of the rows being compared has some but not all 
        # scores missing. Any of the other rows being compared could have none or all missing values. Marks such cases for
        # individual reveiw.
        multiple_count > 1 & same_score == FALSE & any(all_na == "some")                        ~ "Individual review",
        
        # Case when the error is present, the scores are not identical and all the rows being compared have no missing scores.
        multiple_count > 1 & same_score == FALSE & all(all_na == "none")                        ~ "Individual review",
        
        # case when there is no error
        multiple_count == 1                                                                     ~ "No",
        
        # Marks only the most recent of identical rows where error is present for keeping while the other rows are removed.
        multiple_count > 1 & same_score == TRUE & most_recent == "Yes"                          ~ "No",
        
        # Case when there is an error and the scores being compared are not the same. Marks rows where there are no missing scores
        # for keeping
        multiple_count > 1 & same_score == FALSE & all_na == "none"                             ~ "No",
       
        # Case when error is present but all the rows are identical in terms of assigned scores. Marks rows that are not the most
        # recent for removal
        multiple_count > 1 & same_score == TRUE & most_recent == "No"                           ~ "Yes",
       
        # Case when the error is present and the scores are not identical. Marks rows where all the scores are missing for removal
        multiple_count > 1 & same_score == FALSE & all_na == "all"                              ~ "Yes"
      )
    )
  
  # Return result
  multiple_assessment
}

# For testing
# error_check(initial_e) |> 
#   filter(multiple_count > 1)
```

```{r}
# Initial Assessments

initial_e <- error_check(initial_e)

initial_e %>% filter(multiple_count > 1) 
```

```{r}

# Secondary Assessments

secondary_e <- error_check(secondary_e)

secondary_e %>% filter(multiple_count > 1)
```

```{r}
# Post-detect assessments

post_detect_e <- error_check(post_detect_e)

post_detect_e %>% filter(multiple_count > 1)
```


### Create subsets for the 3 assessment types with the multiple assessment rows removed

Create a function that will remove the rows with issues.

```{r}
fix_error <- function(assessment) {
  # Remove rows marked by the error_check function for removal.
  assessment <-  assessment %>% filter(!(remove == "Yes")) 
  
  # Remove rows marked by the error_check function for individual review that are not the most recent.
  assessment <-  assessment %>% filter(!(remove == "Individual review" & most_recent == "No") | remove == "No") 
    
}

```

```{r}
# Initial assessment
initial <- fix_error(initial_e)

# Secondary assessment
secondary <- fix_error(secondary_e)

# Post-detect assessment
post_detect <- fix_error(post_detect_e)
```

### ðŸ”´ Create overall EM determination columns

For each medstar_id reviewed by the LEAD panel, we want to calculate:

1. Create a column containing the number of positive determinations at each assessment (initial, secondary, and post-DETECT) for each subtype of EM.

2. Create a column containing the proportion (denominator is number of non-missing votes) of positive determinations at each assessment (initial, secondary, and post-DETECT) for each subtype of EM.

### Total and proportion of positive votes for each Medstar iD

Create summary dataframes for each assessment that include calculated columns indicating the total number of positive votes and the proportion of positive votes for each MedStar ID.

#### Create a positive vote summary function that will be applied to each of the three assessment data frames.

```{r}
pos_votes <- function(assessment) {
  assessment %>% 
  group_by(medstar_id) %>% 
  reframe(
    across(
      .cols  = c(physical_abuse_2cat : abandonment_2cat, xc_assessment_screened_2cat),
      .fns   = ~ sum(.x),
      .names = "{col}_t"
    ),
    assessment_type_3cat_f  = unique(assessment_type_3cat_f),
    across(
      .cols  = physical_abuse_2cat_t : xc_assessment_screened_2cat_t,
      .fns   = ~ case_when(
        .x   == 0  ~ 0,
        .x  !=  0  ~ .x/n()
      ),
      .names = "{col}_p"
    )
  ) %>%
  rename_with(
    .cols   = ends_with("_t"), 
    .fn     = ~ gsub("2cat_t", "total", .x)
  ) %>% 
  rename_with(
    .cols   = ends_with("_p"), 
    .fn     = ~ gsub("2cat_t_p", "prop", .x)
  )
}
```

```{r}
# Initial Assessments

initial_pos_votes <- pos_votes(initial)
```

```{r}
# Secondary Assessments

secondary_pos_votes <- pos_votes(secondary)
```

```{r}
# Post-detect assessments

post_detect_pos_votes <- pos_votes(post_detect)
```

### Any positive determinations for each subtypes

3. Create a dichotomous variable that indicates if there were _any_ positive determinations at each assessment (initial, secondary, and post-DETECT) for each subtype of abuse.

```{r}
any_pos <- function(assessment_pos_votes) {
  assessment_pos_votes %>% 
    mutate(
      across(
        .cols   = physical_abuse_total : xc_assessment_screened_total,
        .fn     = ~ case_when(
          .x    == 0 ~ 0,
          .x    >  0 ~ 1
        ),
        .names  = "{col}_any"
      ),
      across(
        .cols   = ends_with("_any"),
        .fns    = ~ factor(.x, 
                      levels = c(0,1),
                      labels = c("No", "Yes")),
      .names = "{col}"
      )
    ) %>%
    rename_with(
      .cols   = ends_with("_any"), 
      .fn     = ~ gsub("total_any", "any", .x)
    )
  
}
```

```{r}
# Initial Assessments

initial_pos_votes <- any_pos(initial_pos_votes)
```

```{r}
# Secondary Assessments

secondary_pos_votes <- any_pos(secondary_pos_votes)
```

```{r}
# Post-detect assessments

post_detect_pos_votes <- any_pos(post_detect_pos_votes)
```

### Majority vote variable for each abuse type

Create columns that indicate the final LEAD Assessment determination based on majority vote. Final determination will be by majority (more than half) vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)

```{r}
final_det <- function(assessment_pos_votes) {
  assessment_pos_votes %>% 
    mutate(
      across(
        .cols   = physical_abuse_prop : xc_assessment_screened_prop,
        .fn     = ~ case_when(
          .x    <= 0.5         ~ 0,
          .x    >  0.5         ~ 1
        ),
        .names  = "{col}_det"
      ),
      across(
        .cols   = ends_with("_det"),
        .fns    = ~ factor(.x, 
                      levels = c(0,1),
                      labels = c("No", "Yes")),
      .names = "{col}"
      )
    ) %>%
    rename_with(
      .cols   = ends_with("_det"), 
      .fn     = ~ gsub("prop_det", "det", .x)
    )
}
```

```{r}
# Initial Assessments

initial_pos_votes <- final_det(initial_pos_votes)
```

```{r}
# Secondary Assessments

secondary_pos_votes <- final_det(secondary_pos_votes)
```

```{r}
# Post-detect assessments

post_detect_pos_votes <- final_det(post_detect_pos_votes)
```

### Any positive determinations across all subtypes

Create a dichotomous variable that indicates if there were _any_ positive determinations at each assessment (initial, secondary, and post-DETECT) across _all_ subtypes of EM.

```{r}
abuse_any <- function(assessment_final_det) {
  assessment_final_det %>%
    mutate(
      abuse_any = case_when(
        if_any(physical_abuse_det : abandonment_det, ~. == "Yes")  ~ 1,
        if_all(physical_abuse_det : abandonment_det, ~. == "No")   ~ 0,
        TRUE                                                       ~ NA
      )
    ) %>%
    mutate(
        abuse_any = factor(
        abuse_any,
        levels = c(0, 1),
        labels = c("No", "Yes")
      )
    )
}
```

```{r}
# Initial Assessments

initial_pos_votes <- abuse_any(initial_pos_votes)
```

```{r}
# Secondary Assessments

secondary_pos_votes <- abuse_any(secondary_pos_votes)
```

```{r}
# Post-detect assessments

post_detect_pos_votes <- abuse_any(post_detect_pos_votes)
```

```{r}
# Merge the initial_pos_votes and secondary_pos_votes data sets, keeping only the secondary_pos_votes for each medstar_id when it is available
final_determination <- initial_pos_votes[!initial_pos_votes$medstar_id %in% secondary_pos_votes$medstar_id,]
final_determination <- rbind(final_determination, secondary_pos_votes)
```

## Set labels

```{r}
# Overall final determination
label(final_determination$physical_abuse_det)         <- "LEAD physical abuse determination"
label(final_determination$sexual_abuse_det)           <- "LEAD sexual abuse determination"
label(final_determination$emotional_psycho_abuse_det) <- "LEAD emotional-psycho abuse determination"
label(final_determination$neglect_det)                <- "LEAD neglect determination"
label(final_determination$self_neglect_det)           <- "LEAD self-neglect determination"
label(final_determination$financial_exploitation_det) <- "LEAD financial exploitation determination"
label(final_determination$abandonment_det)            <- "LEAD abandonment determination"
label(final_determination$abuse_any)                  <- "LEAD any abuse determination"

# Initial positive votes
label(initial_pos_votes$physical_abuse_det)         <- "LEAD physical abuse determination"
label(initial_pos_votes$sexual_abuse_det)           <- "LEAD sexual abuse determination"
label(initial_pos_votes$emotional_psycho_abuse_det) <- "LEAD emotional-psycho abuse determination"
label(initial_pos_votes$neglect_det)                <- "LEAD neglect determination"
label(initial_pos_votes$self_neglect_det)           <- "LEAD self-neglect determination"
label(initial_pos_votes$financial_exploitation_det) <- "LEAD financial exploitation determination"
label(initial_pos_votes$abandonment_det)            <- "LEAD abandonment determination"
label(initial_pos_votes$abuse_any)                  <- "LEAD any abuse determination"

# Secondary positive votes
label(secondary_pos_votes$physical_abuse_det)         <- "LEAD physical abuse determination"
label(secondary_pos_votes$sexual_abuse_det)           <- "LEAD sexual abuse determination"
label(secondary_pos_votes$emotional_psycho_abuse_det) <- "LEAD emotional-psycho abuse determination"
label(secondary_pos_votes$neglect_det)                <- "LEAD neglect determination"
label(secondary_pos_votes$self_neglect_det)           <- "LEAD self-neglect determination"
label(secondary_pos_votes$financial_exploitation_det) <- "LEAD financial exploitation determination"
label(secondary_pos_votes$abandonment_det)            <- "LEAD abandonment determination"
label(secondary_pos_votes$abuse_any)                  <- "LEAD any abuse determination"

# Post-DETECT positive votes
label(post_detect_pos_votes$physical_abuse_det)         <- "LEAD physical abuse determination"
label(post_detect_pos_votes$sexual_abuse_det)           <- "LEAD sexual abuse determination"
label(post_detect_pos_votes$emotional_psycho_abuse_det) <- "LEAD emotional-psycho abuse determination"
label(post_detect_pos_votes$neglect_det)                <- "LEAD neglect determination"
label(post_detect_pos_votes$self_neglect_det)           <- "LEAD self-neglect determination"
label(post_detect_pos_votes$financial_exploitation_det) <- "LEAD financial exploitation determination"
label(post_detect_pos_votes$abandonment_det)            <- "LEAD abandonment determination"
label(post_detect_pos_votes$abuse_any)                  <- "LEAD any abuse determination"

# Socio-demographic variables
label(soc_dem$sode_hispanic_4cat_f)                      <- "Ethnicity (Hispanic)"
label(soc_dem$american_indian_or_alaska_native)          <- "American Indian or Alaska Native"
label(soc_dem$asian)                                     <- "Asian"
label(soc_dem$black_or_african_american)                 <- "Black or African American"
label(soc_dem$native_hawaiian_or_other_pacific_islander) <- "Native Hawaiian or Other Pacific Islander"
label(soc_dem$white)                                     <- "White"
label(soc_dem$other)                                     <- "Other"
label(soc_dem$sode_income_9cat_f)                        <- "Household Income"

# Observational measures variables
label(obs_meas$at_physical_4cat_f)   <- "Medic EM physical abuse assessment"
label(obs_meas$at_sexual_4cat_f)     <- "Medic EM sexual abuse assessment"
label(obs_meas$at_emotional_4cat_f)  <- "Medic EM emotional abuse assessment"
label(obs_meas$at_neglect_4cat_f)    <- "Medic EM neglect assessment"
label(obs_meas$at_abandon_4cat_f)    <- "Medic EM abandonment assessment"
label(obs_meas$at_financial_4cat_f)  <- "Medic EM financial abuse assessment"
label(obs_meas$at_self_4cat_f)       <- "Medic EM self-neglect assessment"
label(obs_meas$medic_abuse_any)      <- "Medic EM any abuse assessment"
label(parti$age)                     <- "Age (in years)"
label(parti$xc_detect_status_2cat_f) <- "Abuse determination at initial 911 call"
```

## Merge participant, observational measures, sociodemographic and LEAD dateframes

```{r}
# Merge subset dfs into a new df
final_determination <- purrr::reduce(list(final_determination, soc_dem, obs_meas, parti), dplyr::left_join, by = 'medstar_id')
final_det_initial   <- purrr::reduce(list(initial_pos_votes, soc_dem, obs_meas, parti), dplyr::left_join, by = 'medstar_id')
final_det_sec       <- purrr::reduce(list(secondary_pos_votes, soc_dem, obs_meas, parti), dplyr::left_join, by = 'medstar_id')
final_det_post      <- purrr::reduce(list(post_detect_pos_votes, soc_dem, obs_meas, parti), dplyr::left_join, by = 'medstar_id')
```

## Create dataframe containing "any abuse" determinations across the 3 assessments
This will be used to check the percent similarity of the final abuse determinations across the assessments.

```{r}
initial_compare <- initial_pos_votes %>% 
  select(medstar_id, abuse_any) %>%
  rename(abuse_any_initial = abuse_any)

secondary_compare <- secondary_pos_votes %>% 
  select(medstar_id, abuse_any) %>%
  rename(abuse_any_sec = abuse_any)

post_compare <- post_detect_pos_votes %>% 
  select(medstar_id, abuse_any) %>%
  rename(abuse_any_post = abuse_any)


assessment_compare <- purrr::reduce(list(initial_compare, secondary_compare, post_compare), dplyr::left_join, by = 'medstar_id') %>%
  mutate(
    same_is = ifelse(is.na(abuse_any_sec), NA, 
      ifelse(abuse_any_initial == abuse_any_sec, 1,0)
      ),
    same_ip = ifelse(is.na(abuse_any_post), NA, 
                      ifelse(abuse_any_initial == abuse_any_post, 1,0)
    ),
    same_ii = ifelse(is.na(abuse_any_initial), NA, 
                      ifelse(abuse_any_initial == abuse_any_initial, 1,0)
    )
  )

```

## Participants interviewed between 05/2022 and 05/2023 with positive screening based on LEAD panel abuse determination 

This subset will be contacted for interviews for sharing their experiences.

```{r}
# Medic F/U assessment Medic abuse determination timestamp
med_time <- observational_measures %>% 
  select(medstar_id, x_created_timestamp)

# Add names from participant data frame since some are missing in the  LEAD assessment data frame. And include column showing participant's willingness to receive another phone call.
names <- participant %>% 
  select(medstar_id, name_full, x_do_not_call_2cat_f, phone)

# Add any_abuse variable from final_det_initial df.

abuse <- final_det_initial %>%
  select(medstar_id, abuse_any)

# Merge data sets and create participant list
interview_list <- purrr::reduce(list(abuse, names, med_time), dplyr::left_join, by = 'medstar_id') %>% 
  filter(
  as_date(x_created_timestamp) >= as_date("2022-05-01") & 
    as_date(x_created_timestamp) <= as_date("2023-05-31") &
    abuse_any == "Yes"
) %>% 
  select(medstar_id, name_full, x_created_timestamp, abuse_any, x_do_not_call_2cat_f, phone)

# Save list as an Excel sheet
# write_xlsx(interview_list, "interview_list.xlsx")
```

# Analaysis

## Number and proportion of assessements completed by type of assesement

How many unique MedStar IDs went to the LEAD panel for review?

```{r, include=FALSE}
unique_medstar_ids <- unique(lpa$medstar_id) |> length()
cat("Unique MedStar ID's =", unique_medstar_ids)
```

### Initial assessment

```{r, include=FALSE}
unique_medstar_ids_initial <- unique(initial$medstar_id) |> length()
cat("Unique MedStar ID's at intitial assessment =", unique_medstar_ids_initial)
```

```{r, include=FALSE}
cat("Proportion of MedStar ID's with an intitial assessment =", unique_medstar_ids_initial/unique_medstar_ids)
```

### Secondary assessment

```{r, include=FALSE}
unique_medstar_ids_secondary <- unique(secondary$medstar_id) |> length()
cat("Unique MedStar ID's at secondary assessment =", unique_medstar_ids_secondary)
```

```{r, include=FALSE}
cat("Proportion of MedStar ID's with an secondary assessment =", unique_medstar_ids_secondary/unique_medstar_ids)
```

### Post-DETECT assessment

```{r, include=FALSE}
unique_medstar_ids_post_detect <- unique(post_detect$medstar_id) |> length()
cat("Unique MedStar ID's at post-DETECT assessment =", unique_medstar_ids_post_detect)
```

```{r, include=FALSE}
cat("Proportion of MedStar ID's with an post-DETECT assessment =", unique_medstar_ids_post_detect/unique_medstar_ids)
```

### Summary table
```{r}
sum_table <- data.frame(
                        Value = c("Unique MedStar ID's at initial assessment", 
                                  "Unique MedStar ID's at secondary assessment", 
                                  "Unique MedStar ID's at post-DETECT assessment", 
                                  "Total unique MedStar ID's across all assessments"),
                        Count = c(unique_medstar_ids_initial, unique_medstar_ids_secondary,
                                  unique_medstar_ids_post_detect, unique_medstar_ids),
                        Proportion = c((unique_medstar_ids_initial/unique_medstar_ids), 
                                       (unique_medstar_ids_secondary/unique_medstar_ids), 
                                       (unique_medstar_ids_post_detect/unique_medstar_ids), 
                                       1)
                        ) %>%
  flextable()
# Set caption

sum_table <- set_caption(sum_table, "Summary of Unique Medstar IDs for the LEAD Assessment Data")
sum_table <- width(sum_table, width = 1.5)


sum_table
```

## Percent Similarity of determinations between the different assessments

Create a table that shows the percent similarity between each of the three assessment types and each of the other types using the dataframe containing "any abuse" determination across the 3 assessments. 

Answers the question: When comparing the one assessment type to the other, what is the percentage of determinations that were the same in another assessment type, using the the smaller variable as the denominator?

### Function
This function takes the name of a variable in the assessment_compare df that indicates whether or not the abuse determinations are the same for specified variables as an input. It computes the percent of abuse determinations that are the same.  
```{r}
similarity <- function(column){
  round(length(which(assessment_compare[[column]] == 1))/length(which(!is.na(assessment_compare[[column]]) == TRUE))*100, digits = 2)  
}
```

### Values
```{r}
# Create values for the table
ii = similarity("same_ii")
is = similarity("same_is")
ip = similarity("same_ip")
```

### Format table
```{r}
sim_table <- data.frame(
                        Value = c("Initial", "Secondary", "Post-DETECT"),
                        Initial     = c(ii, is, ip) 
                        ) %>%
  flextable()
# Set caption
sim_table <- set_caption(sim_table, "Table Showing the Percent Similarity Between the Initial Assessment Determination and the Other Assessment Types")

# format line
std_border = fp_border(color="black")

# Set header labels 

sim_table <- set_header_labels(sim_table, Value = "")
sim_table <- set_header_labels(sim_table, Post_detect = "Post-DETECT")

sim_table <- width(sim_table, width = 2)
sim_table <- vline(sim_table, j = 1, border = std_border)

sim_table
```



## Missing data summary

```{r, fig.width = 20}
fd_m <- final_determination %>% 
  select(
    physical_abuse_det: at_self_4cat_f,  
    )%>% md.pattern(., plot = T, rotate.names = T)
```


# ðŸ”´ NOTE

Before we analyze race, we want to know the number and proportion of determinations overall. Secondarily, we will repeat the analysis by race/ethnicity (and probably a bunch of other characteristics). Let's don't drop any rows yet that have NA for race/ethnicity. Only drop rows that have NA for determinations (hopefully, there aren't any).

### Determinations Overall

#### Final determinations for the secondary assessment except when not available (initial assessment in this case)

```{r}
# Create caption/ title
cap_1  <- "Abuse Determinations Overall - Secondary LEAD Assessment (Initial When Unavailable)"


overall_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + abandonment_det + financial_exploitation_det + self_neglect_det + abuse_any, 
               data = final_determination, 
               caption = cap_1)
overall_tab <- t1flex(overall_tab, tablefn = c("qflextable", "flextable", "regulartable"))
overall_tab <- width(overall_tab, width = 3)
overall_tab <- bold(overall_tab, bold = FALSE, part = "all")
overall_tab
```


#### Final determinations for the intial assessment

```{r}
# Create caption/ title
cap_1  <- "Abuse Determinations Overall - Initial LEAD Assessment"


initial_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + abandonment_det + financial_exploitation_det + self_neglect_det, 
               data = final_det_initial, 
               caption = cap_1)
initial_tab <- t1flex(initial_tab, tablefn = c("qflextable", "flextable", "regulartable"))
initial_tab <- width(initial_tab, width = 3)
initial_tab <- bold(initial_tab, bold = FALSE, part = "all")
initial_tab
```

#### Final determinations for the secondary assessment

```{r}
# Create caption/ title
cap_1  <- "Abuse Determinations Overall - Secondary LEAD Assessment"


sec_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + abandonment_det + financial_exploitation_det + self_neglect_det, 
               data = final_det_sec, 
               caption = cap_1)
sec_tab <- t1flex(sec_tab, tablefn = c("qflextable", "flextable", "regulartable"))
sec_tab <- width(sec_tab, width = 3)
sec_tab <- bold(sec_tab, bold = FALSE, part = "all")
sec_tab
```

#### Final determinations for the post detect assessment

```{r}
# Create caption/ title
cap_1  <- "Abuse Determinations Overall - Post-Detect LEAD Assessment"


post_tab <- table1(~ physical_abuse_det + sexual_abuse_det + emotional_psycho_abuse_det + neglect_det + abandonment_det + financial_exploitation_det + self_neglect_det, 
               data = final_det_post, 
               caption = cap_1)
post_tab <- t1flex(post_tab, tablefn = c("qflextable", "flextable", "regulartable"))
post_tab <- width(post_tab, width = 3)
post_tab <- bold(post_tab, bold = FALSE, part = "all")
post_tab
```


### Race/ Ethnicity stratified by abuse determination

```{r}
# Remove missing rows for LEAD data
fd_na <- final_determination %>% drop_na(physical_abuse_det: 	
xc_assessment_screened_det)
```


#### Abuse Determination Overall by Race/ Ethnicity
The data set includes the Secondary Assessment (initial When unavailable)

```{r}
# Create caption/ title
cap_1  <- "Race/ Ethnicity by LEAD Assessment Abuse Determination"


race_tab <- table1(~ sode_hispanic_4cat_f + american_indian_or_alaska_native + asian + black_or_african_american + native_hawaiian_or_other_pacific_islander + white + other| abuse_any, 
               data = fd_na, 
               caption = cap_1)
race_tab <- t1flex(race_tab, tablefn = c("qflextable", "flextable", "regulartable"))
race_tab <- width(race_tab, width = 1.5)
race_tab <- bold(race_tab, bold = FALSE, part = "all")
race_tab
```

#### Abuse Determination Overall by Household Income
The data set includes the Secondary Assessment (initial When unavailable)

```{r}
# Create caption/ title
cap_1  <- "Household Income by LEAD Assessment Abuse Determination"


income_tab <- table1(~ sode_income_9cat_f | abuse_any, 
               data = fd_na, 
               caption = cap_1)
income_tab <- t1flex(income_tab, tablefn = c("qflextable", "flextable", "regulartable"))
income_tab <- width(income_tab, width = 1.5)
income_tab <- bold(income_tab, bold = FALSE, part = "all")
income_tab
```

#### MedStar Medic and Detect Status at Initial 911 Call vs LEAD Abuse Determination

```{r}
# Create caption/ title
cap_1  <- "MedStar Medic EM Abuse Determinations"


medic_tab <- table1(~ at_physical_4cat_f + at_sexual_4cat_f + at_emotional_4cat_f + at_neglect_4cat_f + at_abandon_4cat_f + at_financial_4cat_f + at_self_4cat_f + medic_abuse_any,
               data = final_determination,
               caption = cap_1)
medic_tab <- t1flex(medic_tab, tablefn = c("qflextable", "flextable", "regulartable"))
medic_tab <- width(medic_tab, width = 3)
medic_tab <- bold(medic_tab, bold = FALSE, part = "all")
medic_tab
```

```{r}
# Create caption/ title
cap_1  <- "Overall MedStar Medic Abuse Determinations and Detect status at Initial 911 Call by Overall LEAD Determinations"


mvl_tab <- table1(~ medic_abuse_any + xc_detect_status_2cat_f | abuse_any,
               data = fd_na,
               caption = cap_1)
mvl_tab <- t1flex(mvl_tab, tablefn = c("qflextable", "flextable", "regulartable"))
mvl_tab <- width(mvl_tab, width = 1.5)
mvl_tab <- bold(mvl_tab, bold = FALSE, part = "all")
mvl_tab
```


# Create Word Document

```{r, echo = FALSE}
# create Word file and object
lead_doc <- read_docx()

# Add title
text_style <- fp_text(font.size = 28)
par_style <- fp_par(text.align = "center")

lead_doc <- body_add_fpar(lead_doc, fpar( ftext("LEAD Data Analysis Tables", prop = text_style), 
                                              fp_p = par_style ) ) %>%
  body_add_par(value = "")

# Add number and proportion of assessments completed by type of assessment table
lead_doc <- lead_doc %>% 
  body_add_flextable(sum_table, align = "left") %>%
  body_add_par(value = "")

# Add similarity percentage table
lead_doc <- lead_doc %>%
  body_add_par("The table below answers the question: When comparing the initial assessment abuse determinations to the other assessments, what is the percentage of determinations that were the same?")%>%
  body_add_par(value = "") %>%
  body_add_flextable(sim_table, align = "left") %>%
  body_add_par(value = "")

# Add final determinations for the secondary assessment except when not available (initial assessment in this case) table
lead_doc <- lead_doc %>% 
  body_add_par("LEAD abuse determination was by majority vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)")%>%
  body_add_par(value = "") %>%
  body_add_flextable(overall_tab, align = "left") %>%
  body_add_par(value = "")

# Add final determinations for the intial assessment table
lead_doc <- lead_doc %>% 
  body_add_flextable(initial_tab, align = "left") %>%
  body_add_par(value = "")

# Add final determinations for the secondary assessment table
lead_doc <- lead_doc %>% 
  body_add_flextable(sec_tab, align = "left") %>%
  body_add_par(value = "")

# Add final determinations for the post detect assessment table
lead_doc <- lead_doc %>% 
  body_add_flextable(post_tab, align = "left") %>%
  body_add_par(value = "")

# Add Abuse Determination Overall by Race/ Ethnicity table
lead_doc <- lead_doc %>% 
  body_add_par("LEAD abuse determination was by majority vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)")%>%
  body_add_par(value = "") %>%
  body_add_flextable(race_tab, align = "left") %>%
  body_add_par(value = "")

# Add Abuse Determination Overall by Household Income Table
lead_doc <- lead_doc %>% 
  body_add_par("LEAD abuse determination was by majority vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)")%>%
  body_add_par(value = "") %>%
  body_add_flextable(income_tab, align = "left") %>%
  body_add_par(value = "")

# Add MedStar Medic EM Abuse Determinations Table
lead_doc <- lead_doc %>% 
  body_add_flextable(medic_tab, align = "left") %>%
  body_add_par(value = "")

# Add MedStar Medic and Detect Status at Initial 911 Call vs LEAD Abuse Determination Table
lead_doc <- lead_doc %>% 
  body_add_par("LEAD abuse determination was by majority vote of the secondary assessment (if one was done) or initial assessment (if a secondary assessment wasn't done)")%>%
  body_add_par(value = "") %>%
  body_add_flextable(mvl_tab, align = "left") 

# print the word document
print(lead_doc, target = "LEAD_data_analysis_tables.docx")
```