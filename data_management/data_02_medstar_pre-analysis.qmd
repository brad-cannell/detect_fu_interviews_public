---
title: "Preparation of MedStar Data for Analyses"
html:
  embed-resources: true
format: html
---

# ‚≠êÔ∏è Overview

## This File

This file performs preparatory modification of the pre-processed MedStar records data to facilitate analyses. **Any and all ID values used in the code are DETECT-assigned based on record-linkage.**

It achieves the following:

-   Basic data checks

    1.  Removal of test records in the MedStar data

    2.  Identification and handling of potentially duplicated records

-   Demographic processing

    3.  Creation of **calculated age**, using incident date and date of birth

    -   Removal of invalid date of birth values (date of birth which matches incident date)

    4.  Creation of separate **race category** and **Hispanic ethnicity category** variables

    -   Dummy variables were created to capture nuance in "select all that apply" responses to race, with an overall category selected utilizing these variables

    -   Hispanic ethnicity was separated from race, similar to US Census definitions

-   DETECT Tool item processing

    5.  A **screening performed** flag was created, indicating if a screening was performed or not

    6.  A **screened positive** flag was created, indicating if one or more DETECT tool question items were answered "yes"

    7.  A **"did not enter the patient's home"** flag was created, indicating if that specific response was indicated for any DETECT tool question item (with the response on the item itself considered equivalent to "unable to assess")

    8.  Individual item responses were coded in human-legible format to reduce the risk of error when processing in R

-   A **subject-level** version of the data was created

    9.  Inconsistent values in demographics were reviewed for broad trends between responses. Where possible and reasonable, the "majority rule" was used.

    10. As our data took place over several years, age was consolidated into an **average age**, using age calculated from the consensus date of birth value at each incident date.

    11. DETECT Tool item processing

    -   Individual question items were coded into "Ever Completed", "Ever Answered 'Yes'", "Ever Answered 'No'", "Ever Answered 'UTA'" dummy variables

    -   An **ever screened**, **ever screened positive**, and **ever intended to report** flag was created for each subject, consolidating all records.
    
We also added basic APS outcomes data, including if there was a matched APS Investigation/Intake based on our linkage maps.

## MedStar Data Background

The MedStar records were originally recorded in Filemaker Pro. Processing of this data was extensive and across multiple data files. These files are documented in the [wiki](https://github.com/brad-cannell/detect_fu_interviews_public/wiki).

The primary files of interest for subject-level interest included participant demographic data in the `participant_import.rds` file [created in a separate Quarto file](https://github.com/brad-cannell/detect_fu_interviews_public/blob/main/data_management/data_01_participant_import.qmd), and the original within-set unique subject ID assignment in `participant_unique_ids.rds` file [created in a separate Quarto file](https://github.com/brad-cannell/detect_fu_interviews_public/blob/main/data_management/unique_person_identification/data_02_unique_person_detect_fu_data.qmd).

These files originally contained 92,160 observations of approximately 30 demographic variables. Refinement of unique subject ID assignments in subject-linkage to APS resulted in 41,955 values of `ms_id`.

## Internal Files

This document was created as part of the DETECT project, specifically the merger of APS and MedStar data for analysis using the full follow-up period data. Internal documents relating to these files, which contain PHI, are securely stored on the research group's SharePoint in the [task notes folder](https://uthtmc.sharepoint.com/:f:/r/sites/SPHDETECT-RPC/Shared%20Documents/DETECT%20R01%202018/02%20Shared%20Folders/DETECT%20Follow-up%20Interview%20Data%20Shared/data/notes_documents?csf=1&web=1&e=gLWUzJ).

Notes for the MedStar data are located in the [notes_00_data_medstar.docx](https://uthtmc.sharepoint.com/:w:/r/sites/SPHDETECT-RPC/Shared%20Documents/DETECT%20R01%202018/02%20Shared%20Folders/DETECT%20Follow-up%20Interview%20Data%20Shared/data/notes_documents/notes_00_data_medstar.docx?d=w7367b418df5644fbb3ff5117908f27d9&csf=1&web=1&e=gueXsZ) file.

Please note: as these files contain PHI and proprietary information, they are not publicly available. Links are internal to the research team.

# üì¶ Load Packages and Functions

## Library Imports

```{r}
#| label: imports-libraries
#| warning: FALSE
suppressPackageStartupMessages({
  library(tidyverse)
  library(here)
})
```

### Versioning

This file was created with:

-   R version 4.4.1 ("Race for Your Life").
-   tidyverse version 2.0.0, including all attached packages
-   here version 1.0.1

## Functions

```{r}
#| label: imports-functions
# Function to reduce code repetition in informative imports of data
source(here::here("r", "informative_df_import.R"))
```

# üì• Load Data

## MedStar Data

We loaded our MedStar subject linkage map.

```{r}
#| label: load-ms-subj-map
# Load MedStar Subject ID Map
path <- here::here(
    "data", "cleaned_rds_files", "record_linkage", "maps", 
    "02_medstar-keys-to-id_ms.rds"
    )

informative_df_import(
    "ms_ids", path, overwrite = T
  )

#[PLACEHOLDER]
```

We loaded our MedStar record data, which included participant identifiers and variables specific to the MedStar Response, such as DETECT tool responses. We renamed select variables for use in analyses code. We applied our within-set subject linkage map to obtain our within and between-set subject ID values.

```{r}
#| label: load-ms-data-participants-rds
# Load MedStar Response Data (EMS recorded demographics, DETECT responses)
path <- here::here("data", "unique_id_creation", "participant_unique_id.rds")

informative_df_import(
    "ms_resps", path, overwrite = T
  )

## Clean variable names
ms_resps <- ms_resps |>
  ### Rename variable for compatibility with record linkage map
  dplyr::rename_at("ems_response_number", ~"ems_num") |>
  ### Rename DETECT tool variables for clarity in code
  dplyr::rename_at(
    c(
      "x_unusual_odor", "x_disarray_hoarding_4cat", "x_health_safety_concern",
      "x_isolated_home_4cat", "x_poor_personal_hygiene_4cat",
      "x_inadequately_clothed_4cat", "x_unmet_needs_4cat", "x_depressed_4cat",
      "x_hoarding_medications", "x_difficulty_medications_4cat",
      "x_caregiver_lack_knowledge_4cat", "x_caregiver_unengaged_4cat",
      "x_caregiver_frustrated_4cat", "x_caregiver_anxious_4cat", 
      "x_aps_reported_2cat", "x_aps_reported_confirmation_number"
    ), 
    ~c(
      "dt_env_odor", "dt_env_hoard", "dt_env_concern", "dt_pt_isolated", 
      "dt_pt_hygiene", "dt_pt_clothes", "dt_pt_needs", "dt_pt_depress",
      "dt_pt_med_hoard", "dt_pt_med_diff", "dt_cg_lack", "dt_cg_uneng",
      "dt_cg_frust", "dt_cg_anx", "dt_aps_reported", "dt_aps_report_num"
    )
  )

## Apply Within-Set Subject ID Map
ms_resps <- ms_resps |>
  dplyr::mutate(id = NA_integer_, id_ms = NA_integer_) |>
  dplyr::rows_update(
    ms_ids,
    by = c('x_primary_key', 'medstar_internal_id')
  ) |>
  dplyr::relocate(id, id_ms)

#[PLACEHOLDER]
```

We cleared our MedStar within-set subject ID linkage map from memory, as it was no longer necessary.

```{r}
#| label: load-clear-ms-subj-map
rm(ms_ids)
```

## APS Record Linkage Data

We loaded our record linkage map connecting MedStar Responses to APS Investigations.

```{r}
#| label: load-case-map
# Load MedStar Response - APS Investigation Record Linkage Map
path <- here::here(
    "data", "cleaned_rds_files", "record_linkage", "maps", 
    "04_medstar-records_to_aps-case-invs.rds"
    )

informative_df_import(
    "aps_inv_map", path, overwrite = T
  )

#[PLACEHOLDER]
```

We loaded our record linkage map connecting MedStar Responses to APS Intakes.

```{r}
#| label: load-intake-map
# Load MedStar Response - APS Intake Record Linkage Map
path <- here::here(
    "data", "cleaned_rds_files", "record_linkage", "maps", 
    "05_medstar-records_to_aps-intakes.rds"
    )

informative_df_import(
    "aps_intake_map", path, overwrite = T
  )

#[PLACEHOLDER]
```

# Data Preparation

We prepared our MedStar Data for analyses.

## Removal of "Test" Entries

There were several entries that remained in our data set for "Et3" testing records. We removed these from our data set prior to analysis.

```{r}
#| label: clean-remove-tests

# Remove test records
ms_resps <- ms_resps |>
  dplyr::mutate(
    drop_flag = stringr::str_detect(stringr::str_to_lower(name_full), "et3")
    ) |>
  dplyr::filter(!drop_flag | is.na(drop_flag))
```

## Examination of Potentially Duplicated Responses

Our data was expected to have a unique combination of subject ID and EMS Response number for each row. However, we found that we had 24 rows, representing 12 unique keys, which appeared to be duplicates. These were not resolvable by broad deduplication, indicating that at least one value differed between records. Resolution of these differences thus required additional examination.

```{r}
#| label: clean-check-dup-keys
# Check for duplicate key values (ID, EMS NUM)
## Extract a subset of just the duplicated response keys
dup_resps <- ms_resps |>
  dplyr::mutate(
    key = paste(id, ems_num, sep = '_')
    ) |>
  dplyr::filter(duplicated(key)|duplicated(key, fromLast = T))


## Human-legible summary text
paste0(
  "There were ", 
  format(nrow(dup_resps), big.mark = ','), 
  " responses in the duplicated set, representing ", 
  format(length(unique(dup_resps$key)), big.mark = ',' ), 
  " duplicated response keys. This reduced to ",
  format(nrow(dup_resps |> dplyr::distinct()), big.mark = ','),
  " responses representing ",
  format(nrow(
    dup_resps |> 
      dplyr::distinct() |> 
      dplyr::select(key) |> 
      dplyr::distinct()
      ), big.mark = ',' 
    ),
  " duplicated responses after simple deduplication."
)
# [1] "There were 24 responses in the duplicated set, representing 12 
# duplicated response keys. This reduced to 24 responses representing 12 
# duplicated responses after simple deduplication."
```

Thorough examination appeared to indicate that these responses were generated by multiple-unit responses, such as cases when care was transferred to a different EMS crew or an assist was required.

For 5 of these 12 responses, all DETECT-related variables were identical. For 2 additional responses, there was an explicit mention that the recording unit was not the primary responding unit ("Transfer of Care (Ground)", "Assist, Unit"), and there was less complete overall data within the response for the "secondary" unit's record. The remaining 5 responses required more detailed manual review, which overall selected the most complete appearing record for each individual EMS response where there was any difference in DETECT-Tool use or other pertinent variable values.

We flagged all responses with duplicate rows, and marked the specific rows we wished to omit from analyses.

```{r}
#| label: clean-flag-dups
# Flag Duplicate Responses and Mark Omissions from Analyses.
## Obtain count of DETECT-tool variables missing values
dup_resps$dt_nas <- rowSums(is.na(
  dup_resps |> 
    dplyr::select(dplyr::all_of(c(
      dplyr::starts_with("dt_env"), dplyr::starts_with("dt_pt"), 
      dplyr::starts_with("dt_cg"), dplyr::starts_with("dt_aps")
    )))), 
  na.rm = T
  )

## Build map of duplicated responses to drop in analyses (flags)
dup_resps <- dup_resps |>
  dplyr::mutate(
    ### Flag all of these values as duplicated keys
    dup_key = T,
    ### Flag keys to drop when doing analyses
    dup_drop = dplyr::case_when(
      ### Response-specific judgement (5 responses)
      #### Drop response that was less complete, based on PHI-free value diffs
      stringr::str_detect(key, '426_2598') & dt_pt_med_hoard != 8 ~ T,
      stringr::str_detect(key, '620_1295') & dt_nas > 10 ~ T,
      stringr::str_detect(key, '699_2554') & is.na(dt_aps_report_num) ~ T,
      stringr::str_detect(key, '772_1870') & is.na(symptom_list) ~ T,
      #### Otherwise, drop responses that indicated non-primary response unit
      incident_result %in% c("Transfer of Care (Ground)", "Assist, Unit") ~ T,
      TRUE ~ F
    )
  ) |>
  ### For remaining duplicate responses, random choice is acceptable as all
  ### DETECT-related variables for responses are identical
  dplyr::arrange(key, dplyr::desc(dup_drop)) |>
  group_by(key) |>
  dplyr::mutate(
    dup_drop = c(TRUE, FALSE)
  ) |>
  dplyr::ungroup() |>
  #### Reduce to record-level keys of 'medstar_id', 'x_primary_key', and flags 
  dplyr::select(medstar_id, x_primary_key, dup_key, dup_drop) |>
  #### Ensure distinct values - no duplicate determinations!
  dplyr::distinct()

## Add flags to analysis data  
ms_resps <- ms_resps |>
  dplyr::mutate(
    dup_key = F,
    dup_drop = F
  ) |>
  dplyr::rows_update(
    dup_resps,
    by = c('medstar_id', 'x_primary_key')
  )

## Remove flag map
rm(dup_resps)
```

## Patient Demographics

We processed our demographic variables of age, date of birth, sex, race, and ethnicity.

### Response-Level

We first prepared our data at the response level.

#### Age and DOB

There were several questionable age values within our data set, in which a calculated age was different from the age calculated from the incident date and date of birth. The vast majority of these entries differed only in a single year or reflected a likely typo, such as the substitution of a digit that would be adjacent on a number pad. There were also entries which reflected a DOB entry that was the date of the response. Assuming that no subject in the data set was a neonate born on the date of the response, we considered those DOB values invalid.

```{r}
#| label: clean-demo-age-explore

# Identify major trends in Age/DOB discrepancies

## Extract subset of subjects with more than one DOB value
checking <- ms_resps |>
  dplyr::select(id, dob) |>
  dplyr::distinct() |>
  dplyr::filter(duplicated(id)|duplicated(id, fromLast = T))

## Extract additional subset of subjects with differences between entered and 
## calculated age values
checking_cols <- ms_resps |>
  dplyr::select(id, ems_num, age, dob, incident_timestamp) |>
  dplyr::mutate(
    age_calc = lubridate::year(
      lubridate::as.period(
        lubridate::interval(
          start = dob, 
          end = lubridate::date(incident_timestamp)
          )
        )
      )
    ) |>
  dplyr::filter(age != age_calc) |>
  dplyr::mutate(age_diff = age - age_calc) |>
  dplyr::arrange(age_diff)

## Generate a brief human-legible summary of the extracted data
paste0(
  format(nrow(checking), big.mark = ','),
  " responses (",
  format(length(unique(checking$id)), big.mark = ','),
  " subjects) have multiple DOB values. Entered age =/= calculated age in ",
  format(nrow(checking_cols), big.mark = ','),
  " responses (",
  format(length(unique((checking_cols$id)))),
  " subjects, ",
  format(length(unique(checking_cols$id[checking_cols$id %in% checking$id]))),
  " with multiple DOBs), range ",
  format(min(checking_cols$age_diff)), " to ",
  format(max(checking_cols$age_diff)),
  " years. Average (absolute) difference of ", 
  format(mean(abs(checking_cols$age_diff)), big.mark = ',', digits = 4),
  " years. " ,
  format(
    nrow(checking_cols[checking_cols$age_diff > 0,])*100 / nrow(checking_cols),
    digits = 4
    ),
  "% positive (entered > calculated). ",
  format(
    nrow(checking_cols[
      (checking_cols$dob == lubridate::date(checking_cols$incident_timestamp)),
      ])
    ),
  " have a DOB that matches the incident date, of which ",
  format(
    nrow(checking_cols[
      (checking_cols$dob == lubridate::date(checking_cols$incident_timestamp))
      & checking_cols$id %in% checking$id,
      ])
    ),
  " also have more than one DOB value."
)

# [1] "1,844 responses (908 subjects) have multiple DOB values. 
# Entered age =/= calculated age in 286 responses (273 subjects, 11 with 
# multiple DOBs), range -20 to 84 years. Average (absolute) difference of 
# 4.647 years. 45.1% positive (entered > calculated). 12 have a DOB that 
# matches the incident date, of which 2 also have more than one DOB value."
```

For subjects with additional DOB values in the data, we took the consistently present DOB value that resulted in a matching calculated and entered age value to be the "true" value. We removed frankly invalid DOB values, present when the incident date and DOB were identical. We calculated age values, and took the entered age if the DOB was missing (or removed as invalid).

```{r}
#| label: clean-demo-age-rows

# Address disparities between age and DOB in individual responses
ms_resps <- ms_resps |>
  ## Fix responses with age differences attributable to typo (with multiple 
  ## DOBs, additional responses with consistent DOBs that match entered and 
  ## calculated age - replace with those DOBs). 
  ## Note: IDs 3078 and 27044 had differences due to DOBs that matched the
  ## incident date (invalid). IDs 29557 and 32562 required additional public
  ## record searches to resolve.
  dplyr::rows_update(
    ms_resps |>
      dplyr::filter(
        id %in% c(
          3078, 27044, 41935, 35681, 10506, 1453, 14880, 2813, 3135, 29957, 
          32562
          )
      ) |>
      dplyr::select(id, ems_num, dob) |>
      dplyr::group_by(id) |>
      ### Manual review indicated that all target IDs had the desired DOB
      ### at the lowest EMS Number value - this is not an inherent trait of
      ### all responses, but a convenient coincidence
      dplyr::filter(ems_num == min(ems_num)) |>
      dplyr::ungroup() |>
      dplyr::select(id, dob),
    by = 'id'
    ) |>
  ## Remove DOB from responses with frankly invalid incident-date DOBs
  dplyr::mutate(
    ### Use dplyr::if_else (not ifelse) to avoid loss of date format integrity
    dob = dplyr::if_else(
      lubridate::date(incident_timestamp) == dob, 
      NA_Date_, 
      dob)
  ) |>
  ## Calculate age from incident date and date of birth
  dplyr::mutate(
    age_calc = dplyr::if_else(
      !is.na(dob),
      lubridate::year(
        lubridate::as.period(
          lubridate::interval(
            start = dob, 
            end = lubridate::date(incident_timestamp)
            )
          )
        ),
      age
    )
  )
```

#### Sex

Biological sex appeared to be input by MedStar medics as a "select one" option. Values for sex were stored in our data as numerical values, representing one of three categorical values: "Male", "Female", or "Unknown (Unable To Determine)". We converted these values into text-based categories for processing in R.

```{r}
#| label: clean-demo-sex-rows

# Convert sex into human-understood text for analyses
ms_resps <- ms_resps |>
  dplyr::mutate(
    sex_cat = dplyr::case_when(
      sex == 1 ~ "male",
      sex == 2 ~ "female",
      sex == 7 ~ "uta",
      TRUE ~ NA_character_
    )
  )
```

#### Race and Ethnicity

We processed our values for race and ethnicity. As the MedStar ePCR platform appeared to allow for selection of race and ethnicity from a "select all that apply" list, any combination of these values was present within a single response. These values appeared to largely follow US Census options. Potential values were noted to be: "White", "Black or African American", "Asian", "American Indian or Alaska Native", "Native Hawaiian or Other Pacific Islander", "Middle Eastern or North African", "Hispanic or Latino", "Other Race", "Not Applicable", and "Not Recorded".

We separated "Hispanic or Latino" into a column separate from race, similar to US Census measures. This impacted 10,685 rows (5,631 subjects). We converted values of "Not Applicable" and "Not Recorded" to missing values (`NA`). We processed race options into individual dummy variables to capture the nuances of the responses. The 297 responses, across 169 subjects, with more than one race value selected had their overall race category changed to "multiracial".

```{r}
#| label: clean-demo-race-rows

# Convert race and ethnicity into separate single categories
ms_resps <- ms_resps |>
  ## Extract Ethnicity (Hispanic or Non-Hispanic)
dplyr::mutate(
  hispanic = dplyr::case_when(
    ### Make flag TRUE if "Hispanic" in race value
    stringr::str_detect(race, "Hispanic") ~ T,
    ### Make flag "NA" if race is missing or equivalent to a missing value
    is.na(race)|race %in% c("Not Recorded", "Not Applicable") ~ NA,
    ### Make the flag "NA if race had multiple selections that included 
    ### "Not Applicable" or "Not Recorded" and any race value other than 
    ### "Hispanic or Latino"
    (
      stringr::str_detect(race, "Not") & 
      stringr::str_detect(race, "(Asian|Other Race|White)")
    ) ~ NA,
    ### Otherwise, make the flag FALSE
    TRUE ~ F
    ),
  ## Create new categorical race variable that holds a single race value
    ### Remove "Hispanic or Latino", "Not Applicable", and "Not Recorded"
    ### values from race
    race_cat_txt = stringr::str_remove_all(
      race, 
      "(Hispanic or Latino|Not Applicable|Not Recorded)"
      ),
    ### Clean commas. Done in separate stages as combined Regex attempts
    ### continually removed *all* commas, which was undesirable
    race_cat_txt = stringr::str_remove(race_cat_txt, ", $"),
    race_cat_txt = stringr::str_replace_all(race_cat_txt, ", ,", ", "),
    race_cat_txt = stringr::str_remove(race_cat_txt, "^, "),
    ### Convert missing strings to missing values
    race_cat_txt = dplyr::na_if(race_cat_txt, ""),
    ### Create single-category dummy variables for individual race values
    race_cat_w = stringr::str_detect(race_cat_txt, "White"),
    race_cat_aa = stringr::str_detect(
      race_cat_txt, 
      "Black or African American"
      ),
    race_cat_asian = stringr::str_detect(race_cat_txt, "Asian"),
    race_cat_aian = stringr::str_detect(
      race_cat_txt, 
      "American Indian or Alaska Native"
      ),
    race_cat_nhpi = stringr::str_detect(
      race_cat_txt, 
      "Native Hawaiian or Other Pacific Islander"
      ),
    race_cat_mena = stringr::str_detect(
      race_cat_txt, 
      "Middle Eastern or North African"
      ),
    race_cat_other = stringr::str_detect(
      race_cat_txt, 
      "Other Race"
      ),
    ### If multiple race values exist, convert entire value to "multiracial"
    ### convert all single-category race values to lowercase
    race_cat_txt = ifelse(
      stringr::str_detect(race_cat_txt, ","), 
      "multiracial", 
      stringr::str_to_lower(race_cat_txt)
      )
  ) |>
  ### Generate a race category variable that's a single word, for use in code
  dplyr::mutate(
    race_cat = dplyr::case_when(
      race_cat_txt %in% c("asian", "multiracial", "white") ~ race_cat_txt,
      race_cat_txt == 'black or african american' ~ "black",
      race_cat_txt == 'american indian or alaska native' ~ "aian",
      race_cat_txt == 'native hawaiian or other pacific islander' ~ "nhpi",
      race_cat_txt == 'middle eastern or north african' ~ "mena",
      race_cat_txt == 'other race' ~ "other",
      TRUE ~ NA_character_
    )
  )
```

### Subject-Level

To perform subject-level analyses, we consolidated all observations for a single subject to determine the single "consensus" value for demographic variables. First, we initiated a frame to store subject-level data.

```{r}
#| label: clean-demo-subj-init

# Initiate subject-level data set
ms_subjs <- ms_resps |>
  ## Calculate number of responses per subject
  dplyr::group_by(id) |>
  dplyr::mutate(
    num_resps = dplyr::n_distinct(ems_num)
  ) |>
  dplyr::ungroup() |>
  ## Reduce to a single row per subject, by IDs
  dplyr::select(id, id_ms, num_resps) |>
  dplyr::distinct() |>
  ## Initiate placeholders for demographic variables
  dplyr::mutate(
    ### Age Variables
    dob = lubridate::NA_Date_, age_avg = NA_real_,
    ### Sex Variable
    sex_cat = NA_character_,
    ### Race/Ethnicity Variables
    hispanic = NA, race_cat = NA_character_, race_cat_txt = NA_character_, 
    race_cat_w = NA, race_cat_aa = NA, race_cat_aian = NA, 
    race_cat_asian = NA, race_cat_nhpi = NA, race_cat_other = NA, 
    race_cat_mena = NA
  )
```

#### Age

There were 897 subjects (4,921 responses) with inconsistent DOB values, reduced to 881 subjects (4,803 responses) if omitting missing values, even after the minor resolutions created in the response-level processing. We consolidated these values by taking the single most common non-missing date of birth value for each subject. We expected subjects to have differing ages due to the multi-year and multi-encounter nature of our data set: 11,153 subjects (52,066 responses) had inconsistent calculated age values, reduced to 11,152 subjects (52,064 responses) after omitting missing age values. We resolved age at the subject level by taking the average value of the ages calculated from the subject-level common date of birth values.

```{r}
#| label: clean-demo-age-subj

# Consolidate DOB and age into singular values for each subject, and add to
# subject-level frame
ms_subjs <- ms_subjs |>
  dplyr::rows_update(
    ms_resps |>
      ## Get updated DOB/Age values from non-NA DOBs. For subjects with only 
      ## NA DOBs, keep the NA and entered ages.
      dplyr::rows_update(
        ms_resps |>
          dplyr::filter(!is.na(dob)) |>
        ### Calculate subject-common date of birth from non-NA entries
          dplyr::group_by(id) |>
          dplyr::mutate(
              dob = lubridate::date(names(which.max(table(
                        na.omit(ms_resps[ms_resps$id %in% id,]$dob)
                    ))))
          ) |>
          dplyr::ungroup() |>
          dplyr::select(id, dob) |>
          dplyr::distinct(),
        by = 'id'
      ) |>
      dplyr::group_by(id) |>
      ## Calculate Age
      dplyr::mutate(
        ### Calculate age from incident date and subject-common date of birth
        age_calc_common = dplyr::if_else(
          !is.na(dob),
          lubridate::year(
            lubridate::as.period(
              lubridate::interval(
                start = dob, 
                end = lubridate::date(incident_timestamp)
                )
              )
            ),
          age_calc
        ),
          ### Consolidate common age by taking the average across encounters
        age_avg = mean(age_calc_common)
      ) |>
      dplyr::ungroup() |>
      dplyr::select(id, dob, age_avg) |>
      ## Reduce to one row per subject
      dplyr::distinct(),
    by = 'id'
    )
```

#### Sex

There were 396 subjects (2,490 responses) with inconsistent values for sex between responses in the data set. "Filling" missing values with values from other observations for the same subject resolved 27 subjects (190 responses), with an additional 48 subjects (345 responses) resolved by similarly filling "unable to assess" values. The remaining 321 subjects (1,955 responses) with a mix of "male" and "female" values were resolved through manual review of trends. Of these, we reviewed all IDs with a majority between 60-75% to one sex (52 "female" majority, 40 "male" majority), with a cursory review of IDs with a greater than 75% majority (77 "female" majority, 43 "male" majority). We additionally inspected the 109 remaining IDs that did not have a majority. Judgement were based on trends, heavy associations of certain names with sex/gender (such as "Daisy" being practically considered as a female-exclusive name), and select review of public records such as obituaries.

```{r}
#| label: clean-demo-sex-subj

# Consolidate to a single sex for each subject
ms_subjs <- ms_subjs |>
  dplyr::rows_update(
    ms_resps |>
    dplyr::select(id, sex_cat) |>
    dplyr::filter(
      ## For select subjects, resolution is achieved by omitting responses with
      ## a missing value for sex
      !(
        is.na(sex_cat) & id %in% c(
          5450, 360, 109, 948, 20, 139, 11144, 15717, 15934, 16724, 1333, 2385, 
          21476, 21653, 21883, 22379, 2075, 24108, 2054, 25203, 28077, 3233, 
          29941, 32278, 33121, 3023, 40244
          )
      ) &
      ## For select subjects, resolution is achieved by omitting responses with
      ## a value of "unable to assess" for sex
      !(
        sex_cat == 'uta' & id %in% c(
          4851, 166, 5893, 7197, 7624, 365, 279, 11556, 12382, 14166, 14211, 
          1064, 14561, 15103, 15762, 1359, 16059, 16910, 18326, 18452, 19382, 
          19957, 20067, 21304, 2298, 2434, 24176, 2680, 25877, 2532, 27204, 
          27755, 30107, 2948, 31758, 31863, 32808, 33006, 33968, 3823, 4344, 
          36003, 36323, 38477, 38505, 3865, 39564, 41486
          )
      )
     ) |>
    ## Manually assign sex value to subjects
    dplyr::mutate(
      sex_cat = dplyr::case_when(
        id %in% c(
          4, 40, 98, 154, 158, 231, 284, 428, 434, 850, 868, 1228, 1614, 1708, 
          1926, 2257, 2365, 2419, 2426, 2435, 2512, 2516, 2615, 3031, 3089, 
          3262, 3287, 3382, 3545, 3672, 3735, 3742, 3756, 3765, 3812, 3842, 
          3843, 3845, 3903, 4229, 4280, 4667, 4772, 4927, 5214, 5373, 5841, 
          5968, 6020, 6131, 6471, 6588, 6737, 6849, 7225, 7427, 7676, 7946, 
          7967, 7976, 7988, 8016, 8288, 8297, 9140, 9476, 9524, 9790, 10549, 
          10677, 10888, 11066, 11131, 11235, 11319, 11731, 12370, 12406, 12594, 
          12864, 13451, 13616, 13702, 13910, 14192, 14285, 14603, 14981, 15165, 
          15170, 15188, 15423, 16068, 16123, 16136, 16215, 16558, 16893, 17349, 
          17582, 17657, 17698, 17980, 17989, 18021, 18045, 18083, 18501, 18554, 
          19052, 19063, 19127, 22048, 23391, 23396, 23542, 23752, 23924, 23981, 
          24063, 24065, 24500, 24675, 24701, 25620, 25754, 25785, 25947, 26399, 
          26915, 27053, 27189, 27327, 27714, 27904, 28070, 28277, 28490, 28588, 
          28629, 28712, 28722, 28835, 28928, 28953, 29048, 29225, 29561, 29968, 
          31359, 31736, 31741, 31754, 32022, 32249, 33016, 33240, 36124, 36147, 
          36355, 36365, 36544, 36561, 36772, 37124, 37567, 37578, 37815, 37929, 
          38024, 38291, 38619, 38736, 38746, 38775, 38831, 40053, 40123, 40258, 
          40823, 40841, 41057, 41602, 41721, 41743, 41812
          ) ~ 'female',
        id %in% c(
          27, 192, 377, 484, 608, 657, 765, 883, 897, 1019, 1056, 1270, 1272, 
          1307, 1334, 1495, 1609, 2066, 2575, 2777, 2802, 2980, 3007, 3769, 
          3962, 3967, 4015, 4095, 4099, 4165, 4400, 4432, 4543, 4778, 5105, 
          5125, 5268, 6147, 6170, 6394, 7057, 7696, 7794, 7840, 7888, 7908, 
          7954, 8374, 8439, 9754, 9900, 10283, 10519, 10786, 10984, 11230, 
          11536, 11554, 11986, 12035, 12061, 12084, 13119, 15648, 15946, 15970, 
          16329, 16339, 16560, 16763, 16869, 17082, 17105, 17816, 18217, 18729, 
          18866, 19460, 19505, 19526, 19965, 20876, 21120, 21530, 21652, 21668, 
          22420, 22421, 22753, 22767, 22891, 23457, 23635, 24846, 25286, 25322, 
          25411, 25654, 25790, 25913, 26018, 26026, 27341, 28871, 30745, 31841, 
          32322, 33166, 33183, 33948, 33974, 34130, 34781, 35390, 35893, 36033, 
          36842, 36867, 36979, 37010, 38357, 38386, 38528, 39059, 39195, 39205, 
          39389, 39814, 40992, 41303, 41417, 41692, 41732, 41824, 408180
        ) ~ 'male',
        TRUE ~ sex_cat
      )
    ) |>
    ## Reduce to one row per subject
    dplyr::distinct(),
  by = 'id'
  )
```

#### Race and Ethnicity

There were a total of 766 subjects (across 4,382 responses) with inconsistencies in values for race and ethnicity: 292 subjects (1,782 responses) were inconsistent only in race values, 42 subjects (212 responses) were inconsistent only in ethnicity values, and 432 subjects (2,388 responses) had inconsistencies in both.

A significant portion of these were due to missingness in the data, when counting a missing value as a distinct value. "Filling" missing values with values from other observations for the same subject reduced the scope of the issue to 552 subjects (2,979 responses): 279 subjects (1,718 responses) were inconsistent only in race values, 1,155 subjects (263 responses) were inconsistent only in ethnicity values, and 10 subjects (106 responses) had inconsistencies in both columns.

We resolved inconsistencies with point-fixes, resulting in manual assignment of race and ethnicity values after manual review of trends for each subject. A subject with a single-value majority (over 60% of responses) was assigned that single value. Otherwise, broader trends and patterns were explored to make a judgement. Where judgement could not be determined (or if the broader trends appeared to reflect a multiracial identity that was inconsistently recognized), all appropriate racial values were assigned to the subject as their "overall" subject-level race values. Notably, 27 subjects appeared to demonstrate inconsistencies due to a "misclick" error: as the MedStar ePCR platform appeared to allow for selection of race and ethnicity from a "select all that apply" list, these subjects had a single value for the majority of responses, with a single response demonstrating a likely accidental selection of an additional value that was not consistently repeated.

```{r}
#| label: clean-demo-race-subj

# Consolidate a single race and ethnicity set for each subject, and add to
# subject-level frame
ms_subjs <- ms_subjs |>
  dplyr::rows_update(
    ms_resps |>
      ## For select subjects, resolution is achieved by omitting responses
      ## with more than one race selection
    dplyr::filter( 
      !(race_cat_txt == 'multiracial' & id %in% c(
        141, 901, 1358, 1399, 1933, 2585, 3049, 15051, 15399, 16637, 16998, 
        17849, 18161, 18226, 18564, 21171, 22569, 24290, 24877, 25265, 28708, 
        34238, 37457, 38183, 40841, 41691, 41812
        ))
    ) |>
      ## For subjects that required manual assignment of race categories, 
      ## revert all race category dummy variables to "FALSE" to permit manual
      ## assignment of more than one race to a single subject
    dplyr::mutate(dplyr::across(
      dplyr::all_of(dplyr::starts_with("race_cat_")) & 
        !dplyr::ends_with("_txt"), 
      ~ifelse(id %in% c(
          111, 159, 193, 423, 993, 1032, 1091, 1176, 1275, 1285, 1490, 1508, 
          1574, 1664, 1919, 1968, 2041, 2160, 2165, 2306, 2392, 2513, 2531, 
          2560, 2733, 2860, 2983, 2992, 3008, 3078, 3104, 3173, 3278, 3306, 
          3379, 3392, 3405, 3566, 3727, 3918, 3993, 4253, 4558, 4572, 4844, 
          4887, 4908, 4927, 5035, 5124, 5125, 5620, 5961, 6020, 6896, 7696, 
          8066, 8494, 8553, 9094, 9128, 9210, 9247, 9337, 9349, 9859, 10385, 
          10481, 10557, 10609, 10650, 10703, 11168, 11388, 11394, 11801, 
          12125, 12201, 12607, 13060, 13926, 14015, 14060, 14222, 14755, 
          15095, 15137, 16980, 17131, 17655, 18547, 18826, 18910, 18991, 
          19102, 19570, 20102, 20298, 20382, 20811, 21458, 21476, 21601, 
          21652, 22269, 22438, 22566, 22930, 23012, 23196, 23412, 23742, 
          24273, 24726, 24820, 25031, 25049, 25232, 25322, 25524, 25721, 
          26019, 27685, 29482, 30269, 31044, 31052, 31184, 31224, 31638, 
          31841, 31863, 31944, 32006, 32185, 32324, 32408, 32679, 33595, 
          33620, 33780, 33847, 33851, 33854, 33913, 34465, 36343, 36365, 
          36679, 36802, 37101, 37177, 37242, 37318, 37527, 37696, 37923, 
          38026, 38094, 38116, 38210, 38254, 38291, 38605, 38684, 39254, 
          39367, 39964, 40150, 40415, 40432, 40646, 40796, 40925, 41964
          ), 
          F, 
          .x
          )
      )) |>
      ## Manually assign Hispanic ethnicity flag to subjects
    dplyr::mutate(
      hispanic = dplyr::case_when(
        id %in% c(
          193, 1285, 23196, 32185, 1091, 2513, 5035, 13060, 32324, 52, 78, 226, 
          231, 539, 628, 905, 1174, 1298, 1389, 1451, 1796, 2108, 2485, 2503, 
          2607, 2799, 2954, 3089, 3167, 3199, 3211, 3489, 3542, 3742, 3758, 
          3878, 4462, 4702, 4709, 4738, 4766, 4873, 4930, 4969, 4981, 5034, 
          5148, 5511, 5625, 5638, 5688, 5718, 6085, 6204, 6267, 6269, 6483, 
          6495, 6978, 7104, 7534, 7601, 8202, 8456, 9049, 9125, 9126, 9283, 
          9640, 9787, 10447, 10542, 10621, 11030, 11112, 11115, 11116, 11216, 
          11400, 11556, 11604, 11629, 11710, 11828, 12571, 14180, 14237, 14347, 
          14484, 14501, 14647, 15045, 15128, 15197, 15459, 15644, 15833, 15835, 
          15933, 16295, 16316, 16408, 16410, 16958, 17093, 17223, 17740, 18045, 
          18764, 18924, 19081, 19367, 19383, 20005, 21034, 21326, 21467, 21469, 
          21859, 22109, 22163, 22206, 22304, 22397, 22533, 22940, 23208, 23280, 
          23635, 23739, 23773, 24114, 24492, 25866, 26133, 26300, 26578, 26925, 
          27161, 27211, 27254, 27755, 28199, 28234, 28335, 28340, 28525, 28588, 
          28674, 28861, 28962, 29294, 29354, 29643, 29725, 29792, 29818, 29881, 
          29888, 29923, 30022, 30130, 30954, 30980, 31395, 31409, 31749, 31856, 
          31969, 32023, 32237, 32302, 32488, 33140, 33373, 33888, 33895, 33971, 
          34293, 34329, 34526, 34558, 34566, 34864, 35651, 35699, 36124, 36130, 
          36147, 36175, 36224, 36237, 36258, 36531, 36659, 36666, 37539, 38398, 
          38568, 38932, 38936, 38942, 39123, 40479, 40701, 41896, 41963
          ) ~ T,
        id %in% c(
          9128, 17655, 40415, 4, 183, 692, 1494, 1835, 1894, 2123, 2666, 2759, 
          2865, 3068, 3162, 3467, 3485, 3681, 3701, 4422, 4627, 4722, 4780, 
          5571, 6015, 6066, 6678, 7014, 10574, 11153, 12988, 13644, 15019, 
          15100, 16127, 16268, 17480, 17725, 18844, 18880, 19162, 22042, 23713, 
          23779, 24830, 25261, 25546, 25932, 26525, 26791, 26815, 30589, 30683, 
          31853, 34034, 34262, 35791, 36657, 37354, 37929, 39878, 40338, 40340, 
          41131, 41436, 41456
          ) ~ F,
        TRUE ~ hispanic
      ),
      ## Manually assign individual race flags to subjects
      race_cat_w = ifelse(
        id %in% c(
          2306, 8066, 37101, 3392, 22269, 23196, 9247, 15137, 21476, 40150, 993, 
          1275, 1490, 1508, 1574, 1664, 1919, 2165, 2531, 2560, 2860, 2983, 
          2992, 3008, 3078, 3104, 3173, 3278, 3379, 3727, 3918, 4253, 5961, 
          6896, 9210, 10385, 12125, 14222, 14755, 16980, 18910, 18991, 19102, 
          20102, 20382, 20811, 22566, 24726, 24820, 25232, 26019, 29482, 31044, 
          31638, 31841, 31863, 31944, 32006, 32679, 33780, 33913, 37177, 37242, 
          37923, 38026, 38210, 38291, 40432, 38605, 423, 38116, 2513, 5035, 
          13060
          ), T, race_cat_w
        ),
      race_cat_aa = ifelse(
        id %in% c(
          193, 1285, 5620, 19570, 31052, 37101, 3392, 22269, 9247, 40925, 111, 
          159, 1032, 1968, 2392, 2733, 3306, 3405, 3566, 3993, 4572, 4887, 
          4908, 4927, 6020, 8553, 9337, 9349, 9859, 10481, 10557, 10609, 10703, 
          11168, 11388, 13926, 14060, 17131, 18547, 20298, 21458, 22438, 22930, 
          23012, 23742, 25322, 27685, 36343, 36802, 37696, 38094, 40646, 40796, 
          12607, 21601, 21652, 1091, 14015
          ), T, race_cat_aa
        ), 
      race_cat_aian = ifelse(
        id %in% c(5620, 32185, 4844, 5124, 31224), T, race_cat_aian
      ),
      race_cat_asian = ifelse(
        id %in% c(
          19570, 31052, 30269, 23196, 2041, 2160, 18826, 24273, 25031, 25524, 
          25721, 33595, 33847, 36365, 36679, 37318, 38254, 39254, 9128, 17655, 
          32324
          ), T, race_cat_asian
      ),
      race_cat_nhpi = ifelse(
        id %in% c(30269, 7696, 9094, 11394, 40415), T, race_cat_nhpi
      ),
      race_cat_other = ifelse(
        id %in% c(
          2306, 8066, 9247, 40150, 1176, 4558, 8494, 10650, 11801, 12201, 15095, 
          23412, 25049, 31184, 32408, 33620, 33851, 33854, 34465, 37527, 38684, 
          39367, 39964, 41964, 5125
          ), T, race_cat_other
      )
    ) |>
    dplyr::group_by(id) |>
      ## For select subjects, resolution is achieved by accepting all
      ## race assignments in the data
    dplyr::mutate(
      dplyr::across(
        dplyr::all_of(dplyr::starts_with("race_cat_")) & 
          !dplyr::ends_with("_txt"), 
        ~ifelse(id %in% c(
          1614, 4474, 9880, 11179, 18654, 18751, 22895, 23869, 30405, 34356, 
          40292, 1694, 4724, 5454, 6982, 12176, 23027, 25192, 27673, 27721, 
          31314, 34092, 36955, 37444, 39024, 29755, 40715, 708, 1127, 1737, 
          2132, 2802, 3171, 4243, 5355, 6509, 7839, 7929, 8032, 9083, 9615, 
          10682, 11245, 11539, 11948, 12777, 14943, 15314, 16530, 19922, 
          20818, 22328, 22369, 23236, 26174, 28030, 29195, 30202, 31411, 
          32597, 32993, 33033, 33506, 35023, 35959, 37759, 39272, 40711, 
          41189, 41269, 41732, 41782, 41901, 41906, 24967, 1810, 2667, 23579, 
          27002, 31901, 30021, 30113, 5766, 10517, 37308, 1810, 2667, 31398, 
          33421, 4665, 3986), 
          sum(.x, na.omit = T) > 0, .x
          )
        )
    ) |>
      ## Fill missing values for flags with any other value for that subject
    tidyr::fill(
      dplyr::all_of(dplyr::starts_with("race_cat_")) & 
        !dplyr::ends_with("_txt"), 
      .direction = 'updown'
      ) |>
    tidyr::fill(hispanic, .direction = 'updown') |>
      ## Reduce to one row per subject
    dplyr::select(
      id, hispanic, 
      (dplyr::all_of(dplyr::starts_with("race_cat_")) & 
        !dplyr::ends_with("_txt"))
      ) |>
    dplyr::distinct() |>
      ## Generate overall race category from race flags
    dplyr::mutate(
      race_cat_txt = dplyr::case_when(
        sum(
          race_cat_w, race_cat_aa, race_cat_aian, race_cat_asian,
            race_cat_nhpi, race_cat_other, race_cat_mena, na.rm = T
          ) > 1 ~ "multiracial",
        race_cat_w ~ 'white',
        race_cat_aa ~ 'black or african american',
        race_cat_aian ~ 'american indian or alaska native',
        race_cat_asian ~ 'asian',
        race_cat_nhpi ~ 'native hawaiian or other pacific islander',
        race_cat_mena ~ 'middle eastern or north african',
        race_cat_other ~ 'other race',
        TRUE ~ NA_character_
      )
    )  |>
    ### Generate a race category variable that's a single word, for use in code
    dplyr::mutate(
      race_cat = dplyr::case_when(
        race_cat_txt %in% c("asian", "multiracial", "white") ~ race_cat_txt,
        race_cat_txt == 'black or african american' ~ "black",
        race_cat_txt == 'american indian or alaska native' ~ "aian",
        race_cat_txt == 'native hawaiian or other pacific islander' ~ "nhpi",
        race_cat_txt == 'middle eastern or north african' ~ "mena",
        race_cat_txt == 'other race' ~ "other",
        TRUE ~ NA_character_
      )
    ) |>
    dplyr::ungroup(),
  by = 'id'
  )

```

## DETECT Tool Variables

We additionally processed our DETECT Tool variables.

### Response-Level

We first counted the number of missing (`NA`) values in DETECT screening items, and the number of items with a positive ("yes", 1) response. We used these counts to flag responses if they contained a DETECT screening (at least one item completed), and determine the screening result (positive for even one "yes" response, otherwise negative if screening was performed).

We also flagged if an option for "did not enter the patient's home" was selected, and converted response variables from numeric to human-legible text-based values.

```{r}
#| label: clean-dt-q-vars-resps

# Process DETECT-Tool Question Variables
## Obtain count of DETECT-tool variables missing values
ms_resps$dt_nas <- rowSums(is.na(
  ms_resps |> 
    dplyr::select(dplyr::all_of(c(
      dplyr::starts_with("dt_env"), dplyr::starts_with("dt_pt"), 
      dplyr::starts_with("dt_cg"), dplyr::starts_with("dt_aps")
    )))), 
  na.rm = T
  )

## Obtain the number of "yes" responses in DETECT question items (1) values
ms_resps$dt_num_pos <- rowSums(
  ms_resps |>
    dplyr::select(dplyr::all_of(c(
      dplyr::starts_with("dt_env"), dplyr::starts_with("dt_pt"), 
      dplyr::starts_with("dt_cg")
      ))) |>
    dplyr::mutate(dplyr::across(dplyr::everything(), ~.x == 1)),
  na.rm = T
  )

## Modify DETECT tool variables for legible output in analyses
ms_resps <- ms_resps |>
  dplyr::mutate(
    ### Flag as a screening if any DETECT tool item was completed
    dt_screened = dt_nas < 16,
    ### Flag if screening was positive or negative (even one "yes" response
    ### within a performed screening). Missing if no screening.
    dt_positive = dplyr::case_when(
      !dt_screened ~ NA,
      dt_screened & dt_num_pos >= 1 ~ T,
      TRUE ~ F
      ),
    ### Flag if "Did not enter patient's home" was selected in items where
    ### it was ever in the data, and a screening was performed
    dt_no_entry = dplyr::case_when(
      !dt_screened ~ NA,
      dt_screened & (dt_env_odor == 3 | dt_env_hoard == 3) ~ T,
      TRUE ~ F
      ),
  ### Convert intent to report variable to a binary logical (TRUE/FALSE)
    dt_aps_reported = dplyr::case_when(
      dt_aps_reported == 0 ~ F,
      dt_aps_reported == 1 ~ T,
      TRUE ~ NA
    )
  ) |> 
  ### Convert numeric DETECT item values to human-legible values. Consolidate
  ### "did not enter patient home" (3) and "unable to assess" (8)
  dplyr::mutate(dplyr::across(
    dplyr::all_of(c(
      dplyr::starts_with("dt_env"), dplyr::starts_with("dt_pt"), 
      dplyr::starts_with("dt_cg")
      )), 
    ~dplyr::case_when(
      .x == 1 ~ 'yes',
      .x == 0 ~ 'no',
      .x == 3 ~ 'uta',
      .x == 8 ~ 'uta',
      TRUE ~ NA_character_
      )
  ))
```

### Subject Level

We performed further consolidation at the subject level, taking an "ever true" approach. We calculated if a subject was ever screened, if screening was ever positive, and if there was ever any recorded reporting intent. We also calculated if each item was ever completed (and ever received a "yes", "no", or "uta" response) for each subject.

```{r}
#| label: clean-dt-q-vars-subj
# Pull subject-level consolidated DETECT-Tool data
## Add placeholders for variables to subject-level data set
ms_subjs <- ms_subjs |>
  dplyr::mutate(
    dt_screened = NA, dt_positive = NA, dt_aps_reported = NA, 
    dt_env_odor_comp = NA, dt_env_odor_yes = NA, dt_env_odor_no = NA, 
    dt_env_odor_uta = NA,
    dt_env_hoard_comp = NA, dt_env_hoard_yes = NA, dt_env_hoard_no = NA, 
    dt_env_hoard_uta = NA, 
    dt_env_concern_comp = NA, dt_env_concern_yes = NA, dt_env_concern_no = NA, 
    dt_env_concern_uta = NA, 
    dt_pt_isolated_comp = NA, dt_pt_isolated_yes = NA, dt_pt_isolated_no = NA, 
    dt_pt_isolated_uta = NA, 
    dt_pt_depress_comp = NA, dt_pt_depress_yes = NA, dt_pt_depress_no = NA, 
    dt_pt_depress_uta = NA, 
    dt_pt_hygiene_comp = NA, dt_pt_hygiene_yes = NA, dt_pt_hygiene_no = NA, 
    dt_pt_hygiene_uta = NA, 
    dt_pt_clothes_comp = NA, dt_pt_clothes_yes = NA, dt_pt_clothes_no = NA, 
    dt_pt_clothes_uta = NA, 
    dt_pt_med_diff_comp = NA, dt_pt_med_diff_yes = NA, dt_pt_med_diff_no = NA, 
    dt_pt_med_diff_uta = NA, 
    dt_pt_med_hoard_comp = NA, dt_pt_med_hoard_yes = NA, 
    dt_pt_med_hoard_no = NA, dt_pt_med_hoard_uta = NA,
    dt_pt_needs_comp = NA, dt_pt_needs_yes = NA, dt_pt_needs_no = NA, 
    dt_pt_needs_uta = NA, 
    dt_cg_lack_comp = NA, dt_cg_lack_yes = NA, dt_cg_lack_no = NA, 
    dt_cg_lack_uta = NA,
    dt_cg_uneng_comp = NA, dt_cg_uneng_yes = NA, dt_cg_uneng_no = NA, 
    dt_cg_uneng_uta = NA, 
    dt_cg_frust_comp = NA, dt_cg_frust_yes = NA, dt_cg_frust_no = NA, 
    dt_cg_frust_uta = NA,
    dt_cg_anx_comp = NA, dt_cg_anx_yes = NA, dt_cg_anx_no = NA, 
    dt_cg_anx_uta = NA
  )

## Extract subject-level summary of DETECT-Tool Use
temp_df <- ms_resps |> 
  ### Omit "Dropped Duplicate" Responses
  dplyr::filter(!dup_drop) |>
  ### Select Key values and DETECT-Tool Items of interest
    dplyr::select(
      id, ems_num, dt_screened, dt_positive, dt_aps_reported,
      dplyr::all_of(c(
        dplyr::starts_with("dt_env"), dplyr::starts_with("dt_pt"),
        dplyr::starts_with("dt_cg")
        ))
    ) |>
  ### Convert Logical variables to character for compatibility in pivots
  dplyr::mutate(
    dt_screened = dplyr::case_when(
      dt_screened ~ 'yes',
      !dt_screened ~ 'no',
      TRUE ~ NA_character_
    ),
    dt_positive = dplyr::case_when(
      dt_positive ~ 'yes',
      !dt_positive ~ 'no',
      TRUE ~ NA_character_
    ),
    dt_aps_reported = dplyr::case_when(
      dt_aps_reported ~ 'yes',
      !dt_aps_reported ~ 'no',
      TRUE ~ NA_character_
    )
  ) |>
  ### Pivot longer (each row representing one item for each response) to
  ### facilitate rapid vector calculations
  tidyr::pivot_longer(
    cols = c(
    'dt_screened', 'dt_positive', 'dt_aps_reported',
    dplyr::all_of(c(
      dplyr::starts_with("dt_env"), dplyr::starts_with("dt_pt"),
      dplyr::starts_with("dt_cg")
      ))
    ),
    names_to = 'item_name',
    values_to = 'item_value'
  ) |>
  ### Create dummy variables indicating the response to each item in 
  ### binary/logical format (was it complete? was it answered 'yes'? etc.)
  dplyr::mutate(
    comp = !is.na(item_value),
    yes = dplyr::case_when(
      is.na(item_value) ~ NA,
      item_value == 'yes' ~ T,
      TRUE ~ F
    ),
    no = dplyr::case_when(
      is.na(item_value) ~ NA,
      item_value == 'no' ~ T,
      TRUE ~ F
    ),
    uta = dplyr::case_when(
      is.na(item_value) ~ NA,
      item_value == 'uta' ~ T,
      TRUE ~ F
    )
  ) |>
  ### Pivot wider to restore the "row as record" format for consolidation
  dplyr::select(-item_value) |>
  tidyr::pivot_wider(
    id_cols = c('id', 'ems_num'),
    names_from = item_name,
    values_from = c(comp, yes, no, uta),
    names_glue = "{item_name}_{.value}"
  ) |>
  ### Create High-Level Flags (Ever Screened, Positive Screen, Report Intent)
  dplyr::group_by(id) |>
  dplyr::mutate(
    #### Flag if subject was EVER screened
    dt_screened = sum(dt_screened_yes, na.rm = T) >= 1,
    #### Flag if subject EVER had a positive screening. Missing value if
    #### never screened
    dt_positive = dplyr::case_when(
      !dt_screened ~ NA,
      dt_screened & sum(dt_positive_yes, na.rm = T) >= 1 ~ T,
      TRUE ~ F
    ),
    #### Flag if subject EVER had recorded intent to report. Missing value if
    #### never screened
    dt_aps_reported = dplyr::case_when(
      !dt_screened ~ NA,
      dt_screened & sum(dt_aps_reported_yes, na.rm = T) >= 1 ~ T,
      TRUE ~ F
    )
  ) |>
  ### Remove unnecessary columns relating to screening performance,
  ### overall screening result, and overall intent to report
  dplyr::select(
    -c(
      dt_screened_comp, dt_screened_yes, dt_screened_uta, dt_screened_no, 
      dt_positive_comp, dt_positive_yes, dt_positive_uta, dt_positive_no,
      dt_aps_reported_comp, dt_aps_reported_yes, dt_aps_reported_uta, 
      dt_aps_reported_no
      )
  ) |>
  dplyr::group_by(id) |>
  ### For each item, by subject (ID), count the number of times the item was
  ### completed, and the number of times each response was recorded
  dplyr::mutate(
    dplyr::across(
      dplyr::all_of(c(
        dplyr::ends_with('_comp'), dplyr::ends_with('_yes'), 
        dplyr::ends_with('_uta'), dplyr::ends_with('_no'))
        ), 
      ~sum(.x, na.rm = T)
      )
    ) |>
  dplyr::ungroup() |>
  ### Reduce to a single row per subject (ID)
  dplyr::select(-ems_num) |>
  dplyr::distinct() |>
  ### Create Item and Answer-Level Flags
  dplyr::mutate(
    #### Convert flag to a missing value if no screening was performed. 
    #### Make the flag TRUE if count is at least 1, otherwise FALSE 
    dplyr::across(
      dplyr::all_of(c(
        dplyr::ends_with('_comp'), dplyr::ends_with('_yes'), 
        dplyr::ends_with('_uta'), dplyr::ends_with('_no'))
        ), 
      ~dplyr::case_when(
        !dt_screened ~ NA,
        .x >= 1 ~ T,
        TRUE ~ F
      )
    ),
    #### Remove "Yes", "No", "UTA" flags (convert to missing values) if the
    #### item was never completed for a subject. 
    #### Note for IMPROVEMENTS: There's likely a better way to do this
    ##### Environmental Question: Hoarding
    dt_env_hoard_yes = ifelse(!dt_env_hoard_comp, NA, dt_env_hoard_yes),
    dt_env_hoard_no = ifelse(!dt_env_hoard_comp, NA, dt_env_hoard_no),
    dt_env_hoard_uta = ifelse(!dt_env_hoard_comp, NA, dt_env_hoard_uta),
    ##### Patient Condition Question: Clothing
    dt_pt_clothes_yes = ifelse(!dt_pt_clothes_comp, NA, dt_pt_clothes_yes),
    dt_pt_clothes_no = ifelse(!dt_pt_clothes_comp, NA, dt_pt_clothes_no),    
    dt_pt_clothes_uta = ifelse(!dt_pt_clothes_comp, NA, dt_pt_clothes_uta),
    ##### Patient Condition Question: Unmet Needs
    dt_pt_needs_yes = ifelse(!dt_pt_needs_comp, NA, dt_pt_needs_yes),
    dt_pt_needs_no = ifelse(!dt_pt_needs_no, NA, dt_pt_needs_no),
    dt_pt_needs_uta = ifelse(!dt_pt_needs_uta, NA, dt_pt_needs_uta),
    ##### Caregiver Question: Anxious
    dt_cg_anx_yes = ifelse(!dt_cg_anx_comp, NA, dt_cg_anx_yes),
    dt_cg_anx_no = ifelse(!dt_cg_anx_no, NA, dt_cg_anx_no),
    dt_cg_anx_uta = ifelse(!dt_cg_anx_uta, NA, dt_cg_anx_uta),
    ##### Caregiver Question: Frustrated
    dt_cg_frust_yes = ifelse(!dt_cg_frust_comp, NA, dt_cg_frust_yes),
    dt_cg_frust_no = ifelse(!dt_cg_frust_no, NA, dt_cg_frust_no),
    dt_cg_frust_uta = ifelse(!dt_cg_frust_uta, NA, dt_cg_frust_uta),
    ##### Caregiver Question: Unengaged
    dt_cg_uneng_yes = ifelse(!dt_cg_uneng_comp, NA, dt_cg_uneng_yes),
    dt_cg_uneng_no = ifelse(!dt_cg_uneng_no, NA, dt_cg_uneng_no),
    dt_cg_uneng_uta = ifelse(!dt_cg_uneng_uta, NA, dt_cg_uneng_uta),
    ##### Caregiver Question: Lacks Knowledge
    dt_cg_lack_yes = ifelse(!dt_cg_lack_comp, NA, dt_cg_lack_yes),
    dt_cg_lack_no = ifelse(!dt_cg_lack_no, NA, dt_cg_lack_no),
    dt_cg_lack_uta = ifelse(!dt_cg_lack_uta, NA, dt_cg_lack_uta)
  )

## Add extracted data to subject-level data set
ms_subjs <- ms_subjs |>
  dplyr::rows_update(
    temp_df,
    by = 'id'
  )

## Remove temporary data frame
rm(temp_df)
```

## APS Outcomes Data

We added APS outcomes data. This included the presence of a matched APS Intake (and reporter type categorization) and presence of a matched APS Investigation (and its overall disposition).

### Record-Level

We consolidated our APS Investigation match data to the record level, and added it to our MedStar Response Level data set.

```{r}
#| label: clean-aps-resp-add-invs
# Add APS Intake Matching Data to MedStar Response Records
## Add placeholder columns to MedStar Response data
ms_resps <- ms_resps |>
  dplyr::mutate(
    aps_inv_window = F,
    aps_inv_window_num = NA_integer_,
    aps_inv_window_dispo = NA_character_,
    aps_inv_window_dispo_best = NA_character_,
    aps_inv_exact = F,
    aps_inv_exact_num = NA_integer_,
    aps_inv_exact_dispo = NA_character_,
    aps_inv_exact_dispo_best = NA_character_
  )

## Get DF of ID - EMS_NUM - MATCH? - DISPO
### MATCH? - DISPO for both Exact and Broad Matching in aggregate across all
### matches of that type. Also have a DISPO_BEST that has the disposition 
### of the "best" match at the stated level.

inv_df <- dplyr::left_join(
  ### AGGREGATE (ALL MATCHES) FLAGS & CONSOLIDATED DISPOSITIONS
  dplyr::rows_update(
    #### Broader window-based matches (response within 30 days of APS Inv.)
    aps_inv_map |>
      dplyr::select(id, ems_num, inv_dispo) |>
      dplyr::group_by(id, ems_num) |>
      dplyr::mutate(
        aps_inv_window_num = max(dplyr::row_number()),
        aps_inv_exact_num = NA_integer_,
        aps_inv_exact = F,
        aps_inv_exact_dispo = NA_character_,
        aps_inv_window = T,
        aps_inv_window_dispo = paste(sort(unique(inv_dispo)), collapse = ', ')
      ) |>
      dplyr::ungroup() |>
      ##### Consolidate Dispositions based on APS Hierarchy, but mark those 
      ##### with a mix of valid and invalid overall dispositions specifically.
      ##### Hierarchy: Valid/Invalid, UTA, Other
      dplyr::mutate(
        aps_inv_window_dispo = dplyr::case_when(
          stringr::str_detect(aps_inv_window_dispo, 'invalid') & 
            stringr::str_detect(aps_inv_window_dispo, ', valid') ~ 
            'mixed_validity',
          stringr::str_detect(aps_inv_window_dispo, 'invalid') ~ "invalid",
          stringr::str_detect(aps_inv_window_dispo, 'valid') ~ 'valid',
          stringr::str_detect(aps_inv_window_dispo, 'utd') ~ "utd",
          stringr::str_detect(aps_inv_window_dispo, 'other') ~ "other",
          TRUE ~ NA_character_
        )
      ) |>
      dplyr::select(-inv_dispo) |>
      dplyr::distinct(),
    #### Narrower direct-overlap (response during open APS Inv.)
    aps_inv_map |>
      dplyr::filter(exact) |>
      dplyr::select(id, ems_num, inv_dispo) |>
      dplyr::group_by(id, ems_num) |>
      dplyr::mutate(
        aps_inv_exact_num = max(dplyr::row_number()),
        aps_inv_exact = T,
        aps_inv_exact_dispo = paste(sort(unique(inv_dispo)), collapse = ', ')
      ) |>
      dplyr::ungroup() |>
      ##### Consolidate Dispositions based on APS Hierarchy, but mark those 
      ##### with a mix of valid and invalid overall dispositions specifically.
      ##### Hierarchy: Valid/Invalid, UTD, Other
      dplyr::mutate(
        aps_inv_exact_dispo = dplyr::case_when(
          stringr::str_detect(aps_inv_exact_dispo, 'invalid') & 
            stringr::str_detect(aps_inv_exact_dispo, ', valid') ~ 
            'mixed_validity',
          stringr::str_detect(aps_inv_exact_dispo, 'invalid') ~ "invalid",
          stringr::str_detect(aps_inv_exact_dispo, 'valid') ~ 'valid',
          stringr::str_detect(aps_inv_exact_dispo, 'utd') ~ "utd",
          stringr::str_detect(aps_inv_exact_dispo, 'other') ~ "other",
          TRUE ~ NA_character_
        )
      ) |>
      dplyr::select(-inv_dispo) |>
      dplyr::distinct() ,
    by = c('id', 'ems_num')
    ),
  ### "BEST" Dispositions only
  dplyr::left_join(
    #### Broader window-based matches (response within 30 days of APS Inv.)
    aps_inv_map |>
      dplyr::filter(best_window) |>
      dplyr::select(id, ems_num, inv_dispo) |>
      dplyr::rename_at('inv_dispo', ~'aps_inv_window_dispo_best'),
    #### Narrower direct-overlap (response during open APS Inv.)
    aps_inv_map |>
      dplyr::filter(best_exact) |>
      dplyr::select(id, ems_num, inv_dispo) |>
      dplyr::rename_at('inv_dispo', ~'aps_inv_exact_dispo_best'),
    by = c('id', 'ems_num')
    ),
  by = c('id', 'ems_num')
  )

## Update MedStar Records data
ms_resps <- ms_resps |>
  dplyr::rows_update(
    inv_df,
    by = c('id', 'ems_num')
  )
```

We consolidated our APS Intake match data to the record level, and added it to our MedStar Response Level data set.

```{r}
#| label: clean-aps-resp-add-intakes

# Add APS Intake Matching Data to MedStar Response Records
## Add placeholder columns to MedStar Response data
ms_resps <- ms_resps |>
  dplyr::mutate(
    aps_intake = F,
    aps_intake_num = NA_integer_,
    aps_intake_poss = NA,
    aps_intake_poss_num = NA_integer_,
    aps_intake_ems = NA,
    aps_intake_ems_num = NA_integer_,
    aps_intake_type = NA_character_
  )

## Obtain DF of 
## ID - EMS_NUM - INTAKE? - BROADER INTAKE? - INTAKE? - EMS EXPLICIT INTAKE?
## and a categorical interpretation of intake reporter type category spread
intake_df <- aps_intake_map |>
  dplyr::select(id, ems_num, reporter_possible, reporter_ems) |>
  dplyr::mutate(
    key = paste(id, ems_num, sep = '_'),
    aps_intake = T
    ) |>
  dplyr::group_by(key) |>
  dplyr::mutate(
  ### Get count of intakes of each reporter type flag
    aps_intake_num = max(dplyr::row_number()),
    aps_intake_poss_num = sum(reporter_possible, na.rm = T),
    aps_intake_ems_num = sum(reporter_ems, na.rm = T),
  ### Consolidate reporter type flags as an "if ever in match set"
    aps_intake_poss =  sum(reporter_possible, na.rm = T) > 0,
    aps_intake_ems = sum(reporter_ems, na.rm = T) > 0
  ) |>
  dplyr::ungroup() |>
  dplyr::select(-c(reporter_possible, reporter_ems, key)) |>
  ### Reduce to single row
  dplyr::distinct() |>
  ### Interpret reporter type category from boolean/logical flag pattern
  dplyr::mutate(
    aps_intake_type = dplyr::case_when(
      aps_intake_ems ~ "EMS (explicit)",
      aps_intake_poss ~ "EMS reasonable",
      !aps_intake_ems & !aps_intake_poss ~ "Not likely to be EMS"
    )
  )

## Update MedStar Records data
ms_resps <- ms_resps |>
  dplyr::rows_update(
    intake_df,
    by = c('id', 'ems_num')
  )
```

### Subject Level

We performed further consolidation at the subject level, taking an "ever true" approach for most columns. If a subject ever had an APS Investigation match (exact and window levels), had a matched APS Intake, and ever had an APS Intake of a possible or explicitly EMS reporter type, those values were "TRUE". We consolidated disposition types using the APS Hierarchy, but explicitly marked records with a mix of "Valid" and "Invalid" dispositions with "Mix of Valid and Invalid Dispositions".

```{r}
#| label: clean-aps-subj
# Pull subject-level consolidated APS Investigation & Intake Match Data
## Add placeholders for variables to subject-level data set
ms_subjs <- ms_subjs |>
  dplyr::mutate(
    aps_inv_exact = NA, aps_inv_exact_num = NA_integer_, 
    aps_inv_window = F, aps_inv_window_num = NA_integer_,
    aps_inv_exact_dispo = NA_character_, 
    aps_inv_exact_dispo_best = NA_character_,
    aps_inv_window_dispo = NA_character_,
    aps_inv_window_dispo_best = NA_character_,
    aps_intake = NA, aps_intake_num = NA_integer_,
    aps_intake_poss = NA, aps_intake_poss_num = NA_integer_, 
    aps_intake_ems = NA, aps_intake_ems_num = NA_integer_,
    aps_intake_type = NA_character_
  )

## Consolidate response level values to subject-level
temp_df <- ms_resps |>
  ### Select ID and APS Outcome variables of interest
  dplyr::select(
    id, aps_inv_exact, aps_inv_exact_num, aps_inv_exact_dispo, 
    aps_inv_exact_dispo_best, 
    aps_inv_window, aps_inv_window_num, aps_inv_window_dispo, 
    aps_inv_window_dispo_best,
    aps_intake, aps_intake_num, aps_intake_poss, aps_intake_poss_num,
    aps_intake_ems, aps_intake_ems_num
    ) |>
  ### Reduce to unique rows
  dplyr::distinct() |>
  ### Fill/Consolidate in values, where NA is the source of the row 
  ### duplication.
  dplyr::group_by(id) |>
  tidyr::fill(aps_inv_exact_dispo, .direction = 'updown') |>
  tidyr::fill(aps_inv_exact_dispo_best, .direction = 'updown') |>
  tidyr::fill(aps_inv_window_dispo, .direction = 'updown') |>
  tidyr::fill(aps_inv_window_dispo_best, .direction = 'updown') |>
  dplyr::mutate(
    dplyr::across(
      c(
        aps_inv_exact, aps_inv_window, aps_intake, aps_intake_poss, 
        aps_intake_ems
        ),
      ~sum(.x,na.rm = T) > 0)
  ) |>
  ### Sum numerical count columns
    dplyr::mutate(
    dplyr::across(
      c(
        aps_inv_exact_num, aps_inv_window_num, aps_intake_num, 
        aps_intake_poss_num, aps_intake_ems_num
      ),
      ~sum(.x, na.rm = T)
      )
  ) |>
  ### Where there are multiple disposition types, get a sorted list
  dplyr::mutate(
    dplyr::across(
      c(
        aps_inv_window_dispo, aps_inv_window_dispo_best, 
        aps_inv_exact_dispo, aps_inv_exact_dispo_best
      ),
    ~paste(sort(unique(.x)), collapse = ', ')
    )
  ) |>
  dplyr::ungroup() |>
  dplyr::mutate(
    ### Consolidate Dispositions based on APS Hierarchy, but mark those with
    ### a mix of valid and invalid overall dispositions specifically.
    ### Hierarchy: Valid/Invalid, UTA, Other
    dplyr::across(
      c(
        aps_inv_window_dispo, aps_inv_window_dispo_best, 
        aps_inv_exact_dispo, aps_inv_exact_dispo_best
      ),
    ~dplyr::case_when(
          stringr::str_detect(.x, 'invalid') & 
            stringr::str_detect(.x, ', valid') ~ 'mixed_validity',
          stringr::str_detect(.x, 'invalid') ~ "invalid",
          stringr::str_detect(.x, 'valid') ~ 'valid',
          stringr::str_detect(.x, 'utd') ~ "utd",
          stringr::str_detect(.x, 'other') ~ "other",
          TRUE ~ NA_character_
        )
    )
  ) |>
  dplyr::mutate(
  ### Interpret reporter type category from boolean/logical flag pattern
    aps_intake_type = dplyr::case_when(
      aps_intake_ems ~ "EMS (explicit)",
      aps_intake_poss ~ "EMS reasonable",
      !aps_intake_ems & !aps_intake_poss ~ "Not likely to be EMS"
    )
  ) |>
  ### Reduce to unique rows
  dplyr::distinct()

## Add extracted data to subject-level data set
ms_subjs <- ms_subjs |>
  dplyr::rows_update(
    temp_df,
    by = 'id'
  )

## Remove temporary data frame
rm(temp_df)
```

# üíæ Save and Export Data

We exported our prepared record-level data set.

```{r}
#| label: save-ms-resps
# Export Record-Level Data
saveRDS(
  ms_resps,
  here::here(
    "data", "cleaned_rds_files", "analysis", 
    "medstar_01_record-lvl.rds"
    )
)
```

We exported our prepared subject-level data set.

```{r}
#| label: save-ms-subjs
# Export Subject-Level Data
saveRDS(
  ms_subjs,
  here::here(
    "data", "cleaned_rds_files", "analysis", 
    "medstar_02_subj-lvl.rds"
    )
)
```

# üßπ Clean up

```{r}
#| label: end-cleanup
rm(list=ls())
```
